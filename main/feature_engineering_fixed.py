#!/usr/bin/env python3
"""
üîß –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô FEATURE ENGINEERING
–°–æ–∑–¥–∞—ë—Ç —Ç–æ–ª—å–∫–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ DATA_FIELDS_USED.md
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Tuple
import logging

logger = logging.getLogger(__name__)

# üìä –†–ê–ó–†–ï–®–Å–ù–ù–´–ï –õ–ê–ì–ò (—Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ)
ALLOWED_LAGS = [1, 3, 7, 14]  # –¥–Ω–∏
ALLOWED_ROLLING_WINDOWS = [3, 7, 14, 30]  # –¥–Ω–∏
ALLOWED_DIFF_WINDOWS = [1, 7]  # –¥–Ω–∏
ALLOWED_TREND_WINDOWS = [7, 14]  # –¥–Ω–∏

# ‚ö†Ô∏è –ü–û–õ–Ø –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø –õ–ê–ì–û–í (–∏—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ)
LAG_FEATURES = [
    'orders', 'avg_order_value', 'delivery_time', 'cancelled_orders',
    'rating', 'new_customers_count', 'marketing_spend', 'promotion_usage'
]

# üìä –ü–û–õ–Ø –î–õ–Ø –°–ö–û–õ–¨–ó–Ø–©–ò–• –°–†–ï–î–ù–ò–•
ROLLING_FEATURES = [
    'orders', 'avg_order_value', 'delivery_time', 'rating', 'marketing_spend'
]

# üîó –†–ê–ó–†–ï–®–Å–ù–ù–´–ï –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø
INTERACTION_PAIRS = [
    ('temperature_celsius', 'is_weekend'),
    ('is_rainy', 'is_holiday'),
    ('marketing_spend', 'is_weekend'),
    ('is_hot', 'delivery_time'),
    ('humidity_percent', 'orders')
]

def validate_no_future_leakage(df: pd.DataFrame, feature_cols: List[str]) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ"""
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —É—Ç–µ—á–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ...")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    forbidden_patterns = ['lag_minus', 'future', 'next_', 'tomorrow']
    
    for pattern in forbidden_patterns:
        forbidden_cols = [col for col in feature_cols if pattern in col.lower()]
        if forbidden_cols:
            raise ValueError(f"‚ùå –ù–∞–π–¥–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –±—É–¥—É—â–µ–≥–æ: {forbidden_cols}")
    
    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ª–∞–≥–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
    lag_cols = [col for col in feature_cols if '_lag_' in col]
    for col in lag_cols:
        try:
            lag_value = int(col.split('_lag_')[-1])
            if lag_value <= 0:
                raise ValueError(f"‚ùå –ù–∞–π–¥–µ–Ω –Ω–µ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ª–∞–≥: {col}")
        except:
            continue  # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    
    logger.info("‚úÖ –£—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±—É–¥—É—â–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

def create_lag_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç –ª–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ)"""
    
    logger.info("üìà –°–æ–∑–¥–∞–Ω–∏–µ –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_with_lags = df.copy()
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω—É, –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ –∏ –¥–∞—Ç–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –ª–∞–≥–æ–≤
    df_with_lags = df_with_lags.sort_values(['restaurant_name', 'platform', 'date'])
    
    created_features = 0
    
    for feature in LAG_FEATURES:
        if feature not in df_with_lags.columns:
            logger.warning(f"‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫ {feature} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue
            
        for lag in ALLOWED_LAGS:
            lag_col_name = f"{feature}_lag_{lag}"
            
            # –°–æ–∑–¥–∞—ë–º –ª–∞–≥ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã (—Ä–µ—Å—Ç–æ—Ä–∞–Ω + –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞)
            df_with_lags[lag_col_name] = df_with_lags.groupby(['restaurant_name', 'platform'])[feature].shift(lag)
            created_features += 1
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_lags

def create_rolling_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ"""
    
    logger.info("üéØ –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫–æ–ª—å–∑—è—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö...")
    
    df_with_rolling = df.copy()
    created_features = 0
    
    for feature in ROLLING_FEATURES:
        if feature not in df_with_rolling.columns:
            continue
            
        for window in ALLOWED_ROLLING_WINDOWS:
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
            rolling_mean_col = f"{feature}_rolling_mean_{window}"
            df_with_rolling[rolling_mean_col] = df_with_rolling.groupby(['restaurant_name', 'platform'])[feature].rolling(
                window=window, min_periods=1).mean().reset_index(level=[0,1], drop=True)
            
            # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
            rolling_std_col = f"{feature}_rolling_std_{window}"
            df_with_rolling[rolling_std_col] = df_with_rolling.groupby(['restaurant_name', 'platform'])[feature].rolling(
                window=window, min_periods=1).std().reset_index(level=[0,1], drop=True)
            
            created_features += 2
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} rolling –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_rolling

def create_diff_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç —Ä–∞–∑–Ω–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    
    logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–Ω–æ—Å—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_with_diffs = df.copy()
    created_features = 0
    
    # –¢–æ–ª—å–∫–æ –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
    diff_features = ['orders', 'avg_order_value', 'rating', 'marketing_spend']
    
    for feature in diff_features:
        if feature not in df_with_diffs.columns:
            continue
            
        for window in ALLOWED_DIFF_WINDOWS:
            diff_col_name = f"{feature}_diff_{window}"
            
            # –†–∞–∑–Ω–æ—Å—Ç—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
            lag_values = df_with_diffs.groupby(['restaurant_name', 'platform'])[feature].shift(window)
            df_with_diffs[diff_col_name] = df_with_diffs[feature] - lag_values
            created_features += 1
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} —Ä–∞–∑–Ω–æ—Å—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_diffs

def create_trend_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    
    logger.info("üìâ –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_with_trends = df.copy()
    created_features = 0
    
    trend_features = ['orders', 'rating', 'delivery_time']
    
    for feature in trend_features:
        if feature not in df_with_trends.columns:
            continue
            
        for window in ALLOWED_TREND_WINDOWS:
            trend_col_name = f"{feature}_trend_{window}"
            
            # –ü—Ä–æ—Å—Ç–æ–π —Ç—Ä–µ–Ω–¥ –∫–∞–∫ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —Ç–µ–∫—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏ —Å—Ä–µ–¥–Ω–∏–º –∑–∞ –ø–µ—Ä–∏–æ–¥
            rolling_mean = df_with_trends.groupby(['restaurant_name', 'platform'])[feature].rolling(
                window=window, min_periods=1).mean().reset_index(level=[0,1], drop=True)
            
            df_with_trends[trend_col_name] = df_with_trends[feature] - rolling_mean
            created_features += 1
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_trends

def create_interaction_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    
    logger.info("üîó –°–æ–∑–¥–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_with_interactions = df.copy()
    created_features = 0
    
    for feature1, feature2 in INTERACTION_PAIRS:
        if feature1 in df_with_interactions.columns and feature2 in df_with_interactions.columns:
            interaction_name = f"{feature1}_{feature2}_interaction"
            
            # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
            df_with_interactions[interaction_name] = df_with_interactions[feature1] * df_with_interactions[feature2]
            created_features += 1
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_interactions

def create_aggregate_features(df: pd.DataFrame) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    
    logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_with_aggs = df.copy()
    created_features = 0
    
    # –†–∞—Ç–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–∏
    if 'cancelled_orders' in df_with_aggs.columns and 'orders' in df_with_aggs.columns:
        df_with_aggs['cancel_rate'] = df_with_aggs['cancelled_orders'] / (df_with_aggs['orders'] + 1e-6)
        created_features += 1
    
    if 'new_customers_count' in df_with_aggs.columns and 'total_customers_count' in df_with_aggs.columns:
        df_with_aggs['new_customer_rate'] = df_with_aggs['new_customers_count'] / (df_with_aggs['total_customers_count'] + 1e-6)
        created_features += 1
    
    if 'marketing_spend' in df_with_aggs.columns and 'orders' in df_with_aggs.columns:
        df_with_aggs['marketing_efficiency'] = df_with_aggs['orders'] / (df_with_aggs['marketing_spend'] + 1e-6)
        created_features += 1
    
    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if 'peak_hour_orders' in df_with_aggs.columns and 'off_peak_orders' in df_with_aggs.columns:
        df_with_aggs['peak_to_offpeak_ratio'] = df_with_aggs['peak_hour_orders'] / (df_with_aggs['off_peak_orders'] + 1e-6)
        created_features += 1
    
    logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {created_features} –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    return df_with_aggs

def prepare_features_fixed(df: pd.DataFrame) -> pd.DataFrame:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –∫–∞—á–µ—Å—Ç–≤–∞
    
    Args:
        df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        
    Returns:
        DataFrame —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    """
    
    logger.info("üîß –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    logger.info(f"üìä –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df.columns)}")
    
    if df.empty:
        logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π DataFrame, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å")
        return df
    
    try:
        # 1. –°–æ–∑–¥–∞—ë–º –ª–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_featured = create_lag_features(df)
        
        # 2. –°–æ–∑–¥–∞—ë–º —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ  
        df_featured = create_rolling_features(df_featured)
        
        # 3. –°–æ–∑–¥–∞—ë–º —Ä–∞–∑–Ω–æ—Å—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_featured = create_diff_features(df_featured)
        
        # 4. –°–æ–∑–¥–∞—ë–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_featured = create_trend_features(df_featured)
        
        # 5. –°–æ–∑–¥–∞—ë–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_featured = create_interaction_features(df_featured)
        
        # 6. –°–æ–∑–¥–∞—ë–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_featured = create_aggregate_features(df_featured)
        
        # 7. –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        feature_cols = [col for col in df_featured.columns if col not in ['date', 'restaurant_name', 'total_sales']]
        validate_no_future_leakage(df_featured, feature_cols)
        
        logger.info(f"‚úÖ –ò—Ç–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_featured.columns)} (+{len(df_featured.columns) - len(df)})")
        logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        
        return df_featured
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        raise

def clean_features(df: pd.DataFrame) -> pd.DataFrame:
    """–û—á–∏—â–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç NaN –∏ –≤—ã–±—Ä–æ—Å–æ–≤"""
    
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    df_clean = df.copy()
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –Ω—É–ª—è–º–∏ –¥–ª—è –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    df_clean[numeric_cols] = df_clean[numeric_cols].fillna(0)
    
    # –£–¥–∞–ª—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    df_clean = df_clean.replace([np.inf, -np.inf], 0)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±—Ä–æ—Å—ã (–ø–æ 99-–º—É –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—é)
    for col in numeric_cols:
        if col not in ['date', 'restaurant_name']:
            p99 = df_clean[col].quantile(0.99)
            p01 = df_clean[col].quantile(0.01)
            df_clean[col] = df_clean[col].clip(lower=p01, upper=p99)
    
    logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    return df_clean

def prepare_for_model(df: pd.DataFrame, target_col: str = 'total_sales') -> Tuple[pd.DataFrame, List[str]]:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        df: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        target_col: –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        
    Returns:
        Tuple –∏–∑ (–ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame, —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
    """
    
    logger.info("ü§ñ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏...")
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    exclude_cols = {
        'date', 'restaurant_name', target_col,
        'weather_condition',  # –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è
        'platform'  # –±—É–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω–æ
    }
    
    # –≠–Ω–∫–æ–¥–∏–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É
    df_model = df.copy()
    if 'platform' in df_model.columns:
        df_model['platform_grab'] = (df_model['platform'] == 'grab').astype(int)
        df_model['platform_gojek'] = (df_model['platform'] == 'gojek').astype(int)
    
    # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_cols = [col for col in df_model.columns 
                   if col not in exclude_cols and df_model[col].dtype in ['int64', 'float64']]
    
    logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(feature_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏")
    
    return df_model, feature_cols

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ feature engineering
    import logging
    logging.basicConfig(level=logging.INFO)
    
    print("üß™ –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û FEATURE ENGINEERING")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    np.random.seed(42)
    dates = pd.date_range('2025-04-01', '2025-06-30', freq='D')
    
    test_data = []
    for restaurant in ['Ika Canggu', 'Prana']:
        for platform in ['grab', 'gojek']:
            for date in dates:
                test_data.append({
                    'date': date,
                    'restaurant_name': restaurant,
                    'platform': platform,
                    'total_sales': np.random.uniform(500, 1500),
                    'orders': np.random.randint(10, 50),
                    'avg_order_value': np.random.uniform(20, 60),
                    'delivery_time': np.random.uniform(20, 40),
                    'rating': np.random.uniform(3.5, 5.0),
                    'marketing_spend': np.random.uniform(0, 200),
                    'is_weekend': date.weekday() >= 5,
                    'temperature_celsius': np.random.uniform(25, 35)
                })
    
    test_df = pd.DataFrame(test_data)
    
    try:
        # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        featured_df = prepare_features_fixed(test_df)
        print(f"‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω: {len(test_df.columns)} ‚Üí {len(featured_df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –¢–µ—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        model_df, features = prepare_for_model(featured_df)
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏: {len(features)} —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
    except Exception as e:
        print(f"‚ùå –¢–µ—Å—Ç –ø—Ä–æ–≤–∞–ª–µ–Ω: {e}")
    
    print("üèÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")