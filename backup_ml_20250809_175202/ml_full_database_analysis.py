#!/usr/bin/env python3
"""
üî¨ –ü–û–õ–ù–´–ô ML –ê–ù–ê–õ–ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–• (–£–°–¢–ê–†–ï–í–®–ê–Ø –í–ï–†–°–ò–Ø)
–°—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤
"""

import sqlite3
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import json
from datetime import datetime

def load_database():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã"""
    try:
        conn = sqlite3.connect('database.sqlite')
        df = pd.read_sql_query("SELECT * FROM restaurants", conn)
        conn.close()
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        return df
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

def prepare_features(df):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML"""
    try:
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = []
        feature_names = []
        
        # –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_cols = ['rating', 'orders', 'avg_order_value']
        for col in numeric_cols:
            if col in df.columns:
                features.append(df[col].fillna(0))
                feature_names.append(col)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'platform' in df.columns:
            platform_dummies = pd.get_dummies(df['platform'], prefix='platform')
            for col in platform_dummies.columns:
                features.append(platform_dummies[col])
                feature_names.append(col)
        
        if 'city' in df.columns:
            city_dummies = pd.get_dummies(df['city'], prefix='city')
            for col in city_dummies.columns:
                features.append(city_dummies[col])
                feature_names.append(col)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        X = np.column_stack(features) if features else np.array([]).reshape(len(df), 0)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {X.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return X, feature_names
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        return None, None

def train_ml_model(X, y, feature_names):
    """–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏"""
    try:
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        train_mae = mean_absolute_error(y_train, y_pred_train)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = list(zip(feature_names, model.feature_importances_))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        results = {
            "train_mae": train_mae,
            "test_mae": test_mae,
            "train_r2": train_r2,
            "test_r2": test_r2,
            "feature_importance": feature_importance[:10]  # –¢–æ–ø 10
        }
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. Test R¬≤: {test_r2:.3f}")
        return model, results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return None, None

def generate_insights(results, df):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç–æ–≤"""
    insights = []
    
    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if results and 'feature_importance' in results:
        top_features = results['feature_importance'][:3]
        insights.append("üîç –ö–õ–Æ–ß–ï–í–´–ï –§–ê–ö–¢–û–†–´ –£–°–ü–ï–•–ê:")
        for feature, importance in top_features:
            insights.append(f"  - {feature}: {importance:.3f}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –≥–æ—Ä–æ–¥–∞–º
    if 'city' in df.columns and 'sales' in df.columns:
        city_stats = df.groupby('city')['sales'].agg(['mean', 'count']).round(2)
        insights.append("\nüèôÔ∏è –ê–ù–ê–õ–ò–ó –ü–û –ì–û–†–û–î–ê–ú:")
        for city, stats in city_stats.head(5).iterrows():
            insights.append(f"  - {city}: ${stats['mean']:,.2f} (n={stats['count']})")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º
    if 'platform' in df.columns and 'sales' in df.columns:
        platform_stats = df.groupby('platform')['sales'].agg(['mean', 'count']).round(2)
        insights.append("\nüì± –ê–ù–ê–õ–ò–ó –ü–û –ü–õ–ê–¢–§–û–†–ú–ê–ú:")
        for platform, stats in platform_stats.iterrows():
            insights.append(f"  - {platform}: ${stats['mean']:,.2f} (n={stats['count']})")
    
    return "\n".join(insights)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    print("üî¨ –ü–û–õ–ù–´–ô ML –ê–ù–ê–õ–ò–ó –ë–ê–ó–´ –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_database()
    if df is None:
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    if 'sales' not in df.columns:
        print("‚ùå –°—Ç–æ–ª–±–µ—Ü 'sales' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö")
        return
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X, feature_names = prepare_features(df)
    if X is None:
        return
    
    y = df['sales'].fillna(0)
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model, results = train_ml_model(X, y, feature_names)
    if model is None:
        return
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
    print(f"Train MAE: {results['train_mae']:,.2f}")
    print(f"Test MAE: {results['test_mae']:,.2f}")
    print(f"Train R¬≤: {results['train_r2']:.3f}")
    print(f"Test R¬≤: {results['test_r2']:.3f}")
    
    # –ë–∏–∑–Ω–µ—Å-–∏–Ω—Å–∞–π—Ç—ã
    insights = generate_insights(results, df)
    print(f"\n{insights}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    try:
        with open('legacy_ml_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ legacy_ml_results.json")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
    
    print(f"\nüéâ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()