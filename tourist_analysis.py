#!/usr/bin/env python3
import sqlite3
import json
from datetime import datetime, timedelta
import csv

def analyze_tourist_data():
    """–ê–Ω–∞–ª–∏–∑ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞"""
    
    print("üå¥ –ê–ù–ê–õ–ò–ó –¢–£–†–ò–°–¢–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–•")
    print("=" * 50)
    
    try:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Ñ–∞–π–ª –∫–∞–∫ CSV (–∏–Ω–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç)
        with open('tourist_data.xls', 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
            print("üìÑ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞:", len(content), "—Å–∏–º–≤–æ–ª–æ–≤")
            print("üìÑ –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤:")
            print(content[:500])
            
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç: {e}")
    
    # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥
    try:
        # –°–æ–∑–¥–∞–¥–∏–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ë–∞–ª–∏
        print("\nüìä –°–û–ó–î–ê–ù–ò–ï –¢–£–†–ò–°–¢–ò–ß–ï–°–ö–ò–• –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢–û–í:")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã 2024-2025
        try:
            with open('combined_tourist_correlations_2024_2025.json', 'r', encoding='utf-8') as f:
                combined_tourist_data = json.load(f)
                tourist_patterns = combined_tourist_data['seasonal_patterns']
                print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ï —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã 2024-2025 (Kunjungan_Wisatawan_Bali)")
                print(f"   üìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ç—É—Ä–∏—Å—Ç—ã ‚Üî –ø—Ä–æ–¥–∞–∂–∏: {combined_tourist_data['correlation_tourists_sales']:.3f}")
                print(f"   üèñÔ∏è –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ 2024: {combined_tourist_data['analysis_metadata']['total_tourists_2024']:,} —Ç—É—Ä–∏—Å—Ç–æ–≤")
                print(f"   üèñÔ∏è –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ 2025: {combined_tourist_data['analysis_metadata']['total_tourists_2025']:,} —Ç—É—Ä–∏—Å—Ç–æ–≤")
                print(f"   üìÖ –û–±—â–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {combined_tourist_data['analysis_metadata']['total_months_analyzed']} –º–µ—Å—è—Ü–µ–≤")
        except:
            # Fallback –∫ –¥–∞–Ω–Ω—ã–º —Ç–æ–ª—å–∫–æ 2025
            try:
                with open('real_tourist_correlations.json', 'r', encoding='utf-8') as f:
                    real_tourist_data = json.load(f)
                    tourist_patterns = real_tourist_data['seasonal_patterns']
                    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –†–ï–ê–õ–¨–ù–´–ï —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ –ë–∞–ª–∏ 2025 (Kunjungan_Wisatawan_Bali_2025.xls)")
                    print(f"   üìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ç—É—Ä–∏—Å—Ç—ã ‚Üî –ø—Ä–æ–¥–∞–∂–∏: {real_tourist_data['correlation_tourists_sales']:.3f}")
                    print(f"   üèñÔ∏è –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {real_tourist_data['analysis_metadata']['total_tourists']:,} —Ç—É—Ä–∏—Å—Ç–æ–≤")
            except:
                # Fallback –∫ –Ω–∞—É—á–Ω—ã–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º –∏–∑ –ø—Ä–æ–¥–∞–∂
                try:
                    with open('scientific_tourist_coefficients.json', 'r', encoding='utf-8') as f:
                        scientific_data = json.load(f)
                        tourist_patterns = scientific_data['seasonal_patterns']
                        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ù–ê–£–ß–ù–´–ï —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂)")
                except:
                    # Fallback –∫ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º –µ—Å–ª–∏ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
                    print("‚ö†Ô∏è –§–∞–π–ª—ã —Å –Ω–∞—É—á–Ω—ã–º–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
            tourist_patterns = {
                "–≤—ã—Å–æ–∫–∏–π_—Å–µ–∑–æ–Ω": {
                    "–º–µ—Å—è—Ü—ã": [6, 7, 8, 12, 1],  # –ò—é–Ω—å-–ê–≤–≥—É—Å—Ç, –î–µ–∫–∞–±—Ä—å-–Ø–Ω–≤–∞—Ä—å
                    "–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç": 1.25,  # +25% –∫ –ø—Ä–æ–¥–∞–∂–∞–º
                    "–æ–ø–∏—Å–∞–Ω–∏–µ": "–ü–∏–∫ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–µ–∑–æ–Ω–∞ (—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)",
                    "–∏—Å—Ç–æ—á–Ω–∏–∫": "–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ"
                },
                "—Å—Ä–µ–¥–Ω–∏–π_—Å–µ–∑–æ–Ω": {
                    "–º–µ—Å—è—Ü—ã": [4, 5, 9, 10],  # –ê–ø—Ä–µ–ª—å-–ú–∞–π, –°–µ–Ω—Ç—è–±—Ä—å-–û–∫—Ç—è–±—Ä—å
                    "–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç": 1.10,  # +10% –∫ –ø—Ä–æ–¥–∞–∂–∞–º
                    "–æ–ø–∏—Å–∞–Ω–∏–µ": "–°—Ä–µ–¥–Ω–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–∑–æ–Ω (—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)",
                    "–∏—Å—Ç–æ—á–Ω–∏–∫": "–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ"
                },
                "–Ω–∏–∑–∫–∏–π_—Å–µ–∑–æ–Ω": {
                    "–º–µ—Å—è—Ü—ã": [2, 3, 11],  # –§–µ–≤—Ä–∞–ª—å-–ú–∞—Ä—Ç, –ù–æ—è–±—Ä—å
                    "–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç": 0.85,  # -15% –∫ –ø—Ä–æ–¥–∞–∂–∞–º
                    "–æ–ø–∏—Å–∞–Ω–∏–µ": "–ù–∏–∑–∫–∏–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–µ–∑–æ–Ω (—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏)",
                    "–∏—Å—Ç–æ—á–Ω–∏–∫": "–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ"
                }
            }
        
        print("‚úÖ –¢—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ –º–µ—Å—è—Ü–∞–º:")
        monthly_coefficients = {}
        
        for season, data in tourist_patterns.items():
            for month in data["–º–µ—Å—è—Ü—ã"]:
                month_name = [
                    "–Ø–Ω–≤–∞—Ä—å", "–§–µ–≤—Ä–∞–ª—å", "–ú–∞—Ä—Ç", "–ê–ø—Ä–µ–ª—å", "–ú–∞–π", "–ò—é–Ω—å",
                    "–ò—é–ª—å", "–ê–≤–≥—É—Å—Ç", "–°–µ–Ω—Ç—è–±—Ä—å", "–û–∫—Ç—è–±—Ä—å", "–ù–æ—è–±—Ä—å", "–î–µ–∫–∞–±—Ä—å"
                ][month - 1]
                
                monthly_coefficients[month] = {
                    "coefficient": data["–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç"],
                    "season": season,
                    "description": data["–æ–ø–∏—Å–∞–Ω–∏–µ"]
                }
                
                impact = (data["–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç"] - 1) * 100
                print(f"   {month_name}: {impact:+.0f}% ({data['–æ–ø–∏—Å–∞–Ω–∏–µ']})")
        
        return monthly_coefficients
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return {}

def create_ml_analysis():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("\nü§ñ –°–û–ó–î–ê–ù–ò–ï –°–ò–°–¢–ï–ú–´ –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 50)
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    conn = sqlite3.connect('database.sqlite')
    cursor = conn.cursor()
    
    # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
    print("\nüìä –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø:")
    
    cursor.execute("""
        SELECT 
            gs.stat_date,
            gs.sales,
            gs.ads_spend,
            gs.rating,
            gs.orders,
            gs.ads_ctr,
            gs.store_is_closed,
            gs.store_is_busy,
            gs.out_of_stock,
            strftime('%w', gs.stat_date) as weekday,
            strftime('%m', gs.stat_date) as month,
            r.name as restaurant_name,
            gs.restaurant_id
        FROM grab_stats gs
        JOIN restaurants r ON gs.restaurant_id = r.id
        WHERE gs.sales IS NOT NULL
        ORDER BY gs.stat_date, gs.restaurant_id
    """)
    
    ml_data = cursor.fetchall()
    print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(ml_data):,} –∑–∞–ø–∏—Å–µ–π –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞")
    
    # 2. –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    print("\nüîç –ê–ù–ê–õ–ò–ó –í–ê–ñ–ù–û–°–¢–ò –§–ê–ö–¢–û–†–û–í:")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ñ–∞–∫—Ç–æ—Ä–∞–º
    factor_importance = {}
    
    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –±—é–¥–∂–µ—Ç–∞
    high_ads = [row for row in ml_data if row[2] and row[2] > 100000]  # ads_spend > 100k
    low_ads = [row for row in ml_data if row[2] and row[2] <= 100000]
    
    if high_ads and low_ads:
        high_avg = sum(row[1] for row in high_ads if row[1]) / len([row for row in high_ads if row[1]])
        low_avg = sum(row[1] for row in low_ads if row[1]) / len([row for row in low_ads if row[1]])
        ads_impact = (high_avg - low_avg) / low_avg
        factor_importance['ads_budget'] = {
            'impact': ads_impact,
            'description': '–í–ª–∏—è–Ω–∏–µ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –±—é–¥–∂–µ—Ç–∞',
            'samples_high': len(high_ads),
            'samples_low': len(low_ads)
        }
        print(f"   üìà –í—ã—Å–æ–∫–∏–π —Ä–µ–∫–ª–∞–º–Ω—ã–π –±—é–¥–∂–µ—Ç: {ads_impact:+.1%} (–≤—ã–±–æ—Ä–∫–∞: {len(high_ads):,} vs {len(low_ads):,})")
    
    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è —Ä–µ–π—Ç–∏–Ω–≥–∞
    high_rating = [row for row in ml_data if row[3] and row[3] >= 4.5]
    low_rating = [row for row in ml_data if row[3] and row[3] < 4.0]
    
    if high_rating and low_rating:
        high_avg = sum(row[1] for row in high_rating if row[1]) / len([row for row in high_rating if row[1]])
        low_avg = sum(row[1] for row in low_rating if row[1]) / len([row for row in low_rating if row[1]])
        rating_impact = (high_avg - low_avg) / low_avg
        factor_importance['rating_level'] = {
            'impact': rating_impact,
            'description': '–í–ª–∏—è–Ω–∏–µ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ (4.5+ vs <4.0)',
            'samples_high': len(high_rating),
            'samples_low': len(low_rating)
        }
        print(f"   ‚≠ê –í—ã—Å–æ–∫–∏–π —Ä–µ–π—Ç–∏–Ω–≥ (4.5+ vs <4.0): {rating_impact:+.1%} (–≤—ã–±–æ—Ä–∫–∞: {len(high_rating):,} vs {len(low_rating):,})")
    
    # –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è/–∑–∞–Ω—è—Ç–æ—Å—Ç–∏
    closed_busy = [row for row in ml_data if (row[6] and row[6] > 0) or (row[7] and row[7] > 0)]  # closed or busy
    normal = [row for row in ml_data if (not row[6] or row[6] == 0) and (not row[7] or row[7] == 0)]
    
    if closed_busy and normal:
        closed_avg = sum(row[1] for row in closed_busy if row[1]) / len([row for row in closed_busy if row[1]])
        normal_avg = sum(row[1] for row in normal if row[1]) / len([row for row in normal if row[1]])
        operational_impact = (closed_avg - normal_avg) / normal_avg
        factor_importance['operational_issues'] = {
            'impact': operational_impact,
            'description': '–í–ª–∏—è–Ω–∏–µ –∑–∞–∫—Ä—ã—Ç–∏—è/–∑–∞–Ω—è—Ç–æ—Å—Ç–∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞',
            'samples_issues': len(closed_busy),
            'samples_normal': len(normal)
        }
        print(f"   üö´ –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {operational_impact:+.1%} (–≤—ã–±–æ—Ä–∫–∞: {len(closed_busy):,} vs {len(normal):,})")
    
    # 3. –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π
    print("\nüö® –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –î–ï–¢–ï–ö–¶–ò–Ø –ê–ù–û–ú–ê–õ–ò–ô:")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π
    restaurant_data = {}
    for row in ml_data:
        restaurant_id = row[12]
        if restaurant_id not in restaurant_data:
            restaurant_data[restaurant_id] = {
                'name': row[11],
                'sales': [],
                'dates': []
            }
        if row[1]:  # sales not null
            restaurant_data[restaurant_id]['sales'].append(row[1])
            restaurant_data[restaurant_id]['dates'].append(row[0])
    
    anomalies = []
    for restaurant_id, data in restaurant_data.items():
        if len(data['sales']) > 30:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            sales = data['sales']
            mean_sales = sum(sales) / len(sales)
            
            # –ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (–±–æ–ª–µ–µ —á–µ–º –≤ 3 —Ä–∞–∑–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ)
            for i, sale in enumerate(sales):
                if sale > mean_sales * 3 or sale < mean_sales * 0.3:
                    anomalies.append({
                        'restaurant': data['name'],
                        'date': data['dates'][i],
                        'sales': sale,
                        'mean_sales': mean_sales,
                        'deviation': (sale - mean_sales) / mean_sales
                    })
    
    print(f"   üîç –ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {len(anomalies)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –∞–Ω–æ–º–∞–ª–∏–π
    anomalies.sort(key=lambda x: abs(x['deviation']), reverse=True)
    for i, anomaly in enumerate(anomalies[:5]):
        print(f"   {i+1}. {anomaly['restaurant']} ({anomaly['date']}): "
              f"{anomaly['sales']:,.0f} —Ä—É–±. ({anomaly['deviation']:+.0%} –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ)")
    
    # 4. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤
    print("\nüìä –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø –†–ï–°–¢–û–†–ê–ù–û–í:")
    
    restaurant_segments = {}
    for restaurant_id, data in restaurant_data.items():
        if len(data['sales']) > 10:
            avg_sales = sum(data['sales']) / len(data['sales'])
            
            if avg_sales > 3000000:  # > 3M
                segment = "–ü—Ä–µ–º–∏—É–º"
            elif avg_sales > 1500000:  # 1.5M - 3M
                segment = "–°—Ä–µ–¥–Ω–∏–π+"
            elif avg_sales > 800000:   # 800K - 1.5M
                segment = "–°—Ä–µ–¥–Ω–∏–π"
            else:
                segment = "–≠–∫–æ–Ω–æ–º"
            
            restaurant_segments[data['name']] = {
                'segment': segment,
                'avg_sales': avg_sales,
                'total_days': len(data['sales'])
            }
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º
    segments = {}
    for name, info in restaurant_segments.items():
        segment = info['segment']
        if segment not in segments:
            segments[segment] = []
        segments[segment].append((name, info['avg_sales']))
    
    for segment, restaurants in segments.items():
        avg_segment_sales = sum(r[1] for r in restaurants) / len(restaurants)
        print(f"   üè∑Ô∏è  {segment}: {len(restaurants)} —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤, "
              f"—Å—Ä–µ–¥–Ω–µ–µ: {avg_segment_sales:,.0f} —Ä—É–±.")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –≤ —Å–µ–≥–º–µ–Ω—Ç–µ
        restaurants.sort(key=lambda x: x[1], reverse=True)
        for i, (name, sales) in enumerate(restaurants[:3]):
            print(f"      {i+1}. {name}: {sales:,.0f} —Ä—É–±.")
    
    conn.close()
    
    return {
        'factor_importance': factor_importance,
        'anomalies': anomalies[:10],  # –¢–æ–ø-10 –∞–Ω–æ–º–∞–ª–∏–π
        'segments': segments
    }

if __name__ == "__main__":
    try:
        # –ê–Ω–∞–ª–∏–∑ —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        tourist_coefficients = analyze_tourist_data()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ ML –∞–Ω–∞–ª–∏–∑–∞
        ml_results = create_ml_analysis()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        combined_results = {
            'tourist_coefficients': tourist_coefficients,
            'ml_analysis': ml_results,
            'analysis_date': datetime.now().isoformat()
        }
        
        with open('advanced_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(combined_results, f, indent=2, ensure_ascii=False, default=str)
        
        print("\nüéâ –†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ advanced_analysis.json")
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()