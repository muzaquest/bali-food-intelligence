"""
ü§ñ MUZAQUEST ANALYTICS - –ü–û–õ–ù–´–ô ML –ê–ù–ê–õ–ò–ó –í–°–ï–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ 25,129 –∑–∞–ø–∏—Å–µ–π –ø–æ 59 —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º –∑–∞ 2+ –≥–æ–¥–∞ (2023-2025)
"""

import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    from sklearn.ensemble import RandomForestRegressor, IsolationForest
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    import scipy.stats as stats
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

def load_full_database():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞"""
    conn = sqlite3.connect('database.sqlite')
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ Grab –∏ Gojek
    query = """
    SELECT 
        r.name as restaurant_name,
        r.id as restaurant_id,
        'grab' as platform,
        g.stat_date,
        g.sales as total_sales_amount,
        g.orders as total_orders,
        g.rating,
        COALESCE(g.ads_sales, 0) as marketing_spend,
        COALESCE(g.orders - g.cancelled_orders, g.orders) as new_customers,
        COALESCE(g.cancelled_orders, 0) as repeat_customers,
        CASE WHEN g.orders > 0 THEN g.sales / g.orders ELSE 0 END as avg_order_value,
        90.0 as customer_retention_rate,
        COALESCE(g.cancelled_orders, 0) as operational_issues,
        strftime('%w', g.stat_date) as day_of_week,
        strftime('%m', g.stat_date) as month,
        CASE WHEN strftime('%w', g.stat_date) IN ('0', '6') THEN 1 ELSE 0 END as is_weekend
    FROM grab_stats g
    JOIN restaurants r ON g.restaurant_id = r.id
    
    UNION ALL
    
    SELECT 
        r.name as restaurant_name,
        r.id as restaurant_id,
        'gojek' as platform,
        gj.stat_date,
        gj.sales as total_sales_amount,
        gj.orders as total_orders,
        gj.rating,
        COALESCE(gj.ads_sales, 0) as marketing_spend,
        COALESCE(gj.incoming_orders, gj.orders) as new_customers,
        COALESCE(gj.accepted_orders, gj.orders) as repeat_customers,
        CASE WHEN gj.orders > 0 THEN gj.sales / gj.orders ELSE 0 END as avg_order_value,
        COALESCE(gj.realized_orders_percentage, 90.0) as customer_retention_rate,
        COALESCE(gj.cancelled_orders + gj.lost_orders, 0) as operational_issues,
        strftime('%w', gj.stat_date) as day_of_week,
        strftime('%m', gj.stat_date) as month,
        CASE WHEN strftime('%w', gj.stat_date) IN ('0', '6') THEN 1 ELSE 0 END as is_weekend
    FROM gojek_stats gj
    JOIN restaurants r ON gj.restaurant_id = r.id
    
    ORDER BY stat_date, restaurant_name
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    df['stat_date'] = pd.to_datetime(df['stat_date'])
    df['day_of_week'] = df['day_of_week'].astype(int)
    df['month'] = df['month'].astype(int)
    df['is_weekend'] = df['is_weekend'].astype(int)
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    numeric_columns = ['total_sales_amount', 'total_orders', 'rating', 'marketing_spend', 
                      'new_customers', 'repeat_customers', 'avg_order_value', 'customer_retention_rate']
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    return df

def analyze_market_segments():
    """–ê–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—Å–µ–≥–æ —Ä—ã–Ω–∫–∞ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤"""
    print("üîç 1. –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø –†–´–ù–ö–ê –†–ï–°–¢–û–†–ê–ù–û–í")
    print("-" * 50)
    
    df = load_full_database()
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º
    restaurant_stats = df.groupby(['restaurant_name', 'restaurant_id']).agg({
        'total_sales_amount': ['sum', 'mean', 'std'],
        'total_orders': ['sum', 'mean'],
        'rating': 'mean',
        'marketing_spend': 'sum',
        'new_customers': 'sum',
        'repeat_customers': 'sum',
        'avg_order_value': 'mean',
        'customer_retention_rate': 'mean'
    }).round(2)
    
    # –£–ø—Ä–æ—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    restaurant_stats.columns = ['total_revenue', 'avg_daily_revenue', 'revenue_volatility',
                               'total_orders', 'avg_daily_orders', 'avg_rating', 
                               'total_marketing', 'total_new_customers', 'total_repeat_customers',
                               'avg_order_value', 'retention_rate']
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    restaurant_stats['marketing_efficiency'] = restaurant_stats['total_revenue'] / (restaurant_stats['total_marketing'] + 1)
    restaurant_stats['customer_loyalty'] = restaurant_stats['total_repeat_customers'] / (restaurant_stats['total_new_customers'] + 1)
    
    if SKLEARN_AVAILABLE:
        # K-Means –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        features_for_clustering = ['total_revenue', 'avg_rating', 'marketing_efficiency', 
                                  'customer_loyalty', 'avg_order_value', 'retention_rate']
        
        X = restaurant_stats[features_for_clustering].fillna(0)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        silhouette_scores = []
        K_range = range(2, 8)
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = kmeans.fit_predict(X_scaled)
            score = silhouette_score(X_scaled, labels)
            silhouette_scores.append(score)
        
        optimal_k = K_range[np.argmax(silhouette_scores)]
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        restaurant_stats['cluster'] = kmeans.fit_predict(X_scaled)
        
        print(f"‚úÖ –í—ã—è–≤–ª–µ–Ω–æ {optimal_k} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤")
        print(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {max(silhouette_scores):.3f}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        for cluster in range(optimal_k):
            cluster_data = restaurant_stats[restaurant_stats['cluster'] == cluster]
            print(f"\nüéØ –°–ï–ì–ú–ï–ù–¢ {cluster + 1} ({len(cluster_data)} —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤):")
            print(f"   üí∞ –°—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞: {cluster_data['total_revenue'].mean():,.0f} IDR")
            print(f"   ‚≠ê –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {cluster_data['avg_rating'].mean():.2f}")
            print(f"   üìà –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {cluster_data['marketing_efficiency'].mean():.1f}x")
            print(f"   üë• –õ–æ—è–ª—å–Ω–æ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç–æ–≤: {cluster_data['customer_loyalty'].mean():.2f}")
            
            # –¢–æ–ø —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã —Å–µ–≥–º–µ–Ω—Ç–∞
            top_restaurants = cluster_data.nlargest(3, 'total_revenue').index.get_level_values(0).tolist()
            print(f"   üèÜ –õ–∏–¥–µ—Ä—ã: {', '.join(top_restaurants[:3])}")
    
    return restaurant_stats

def detect_market_anomalies():
    """–í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤—Å–µ–≥–æ —Ä—ã–Ω–∫–∞"""
    print("\nüö® 2. –î–ï–¢–ï–ö–¶–ò–Ø –ê–ù–û–ú–ê–õ–ò–ô –í–°–ï–ì–û –†–´–ù–ö–ê")
    print("-" * 50)
    
    df = load_full_database()
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º –¥–ª—è –≤—Å–µ–≥–æ —Ä—ã–Ω–∫–∞
    daily_market = df.groupby('stat_date').agg({
        'total_sales_amount': 'sum',
        'total_orders': 'sum',
        'rating': 'mean',
        'marketing_spend': 'sum'
    }).round(2)
    
    if SKLEARN_AVAILABLE:
        # Isolation Forest –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π
        features = ['total_sales_amount', 'total_orders', 'rating', 'marketing_spend']
        X = daily_market[features].fillna(0)
        
        iso_forest = IsolationForest(contamination=0.05, random_state=42)
        anomalies = iso_forest.fit_predict(X)
        daily_market['is_anomaly'] = anomalies == -1
        
        anomaly_days = daily_market[daily_market['is_anomaly']].sort_values('total_sales_amount')
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(anomaly_days)} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –¥–Ω–µ–π –∏–∑ {len(daily_market)}")
        print(f"üìâ –°–∞–º—ã–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –¥–Ω–∏:")
        
        for i, (date, row) in enumerate(anomaly_days.head(5).iterrows()):
            print(f"   {i+1}. {date.strftime('%Y-%m-%d')}: {row['total_sales_amount']:,.0f} IDR, {row['total_orders']:.0f} –∑–∞–∫–∞–∑–æ–≤")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
    daily_market['sales_change'] = daily_market['total_sales_amount'].pct_change() * 100
    daily_market['orders_change'] = daily_market['total_orders'].pct_change() * 100
    
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–ò:")
    print(f"   üí∞ –°—Ä–µ–¥–Ω—è—è –¥–Ω–µ–≤–Ω–∞—è –≤—ã—Ä—É—á–∫–∞: {daily_market['total_sales_amount'].mean():,.0f} IDR")
    print(f"   üìà –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã—Ä—É—á–∫–∏: {daily_market['sales_change'].std():.1f}%")
    print(f"   üì¶ –°—Ä–µ–¥–Ω–∏–µ –∑–∞–∫–∞–∑—ã –≤ –¥–µ–Ω—å: {daily_market['total_orders'].mean():.0f}")
    print(f"   üìä –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∑–∞–∫–∞–∑–æ–≤: {daily_market['orders_change'].std():.1f}%")
    
    return daily_market

def analyze_success_factors():
    """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —É—Å–ø–µ—Ö–∞ –Ω–∞ –≤—Å–µ–º —Ä—ã–Ω–∫–µ"""
    print("\nüéØ 3. –§–ê–ö–¢–û–†–´ –£–°–ü–ï–•–ê (RANDOM FOREST)")
    print("-" * 50)
    
    df = load_full_database()
    
    if SKLEARN_AVAILABLE:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
        features = ['rating', 'marketing_spend', 'new_customers', 'repeat_customers',
                   'avg_order_value', 'customer_retention_rate', 'operational_issues',
                   'day_of_week', 'month', 'is_weekend']
        
        # –°–æ–∑–¥–∞–µ–º –ª–∞–≥–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        df_sorted = df.sort_values(['restaurant_id', 'stat_date'])
        df_sorted['sales_lag_1'] = df_sorted.groupby('restaurant_id')['total_sales_amount'].shift(1)
        df_sorted['sales_lag_7'] = df_sorted.groupby('restaurant_id')['total_sales_amount'].shift(7)
        
        features.extend(['sales_lag_1', 'sales_lag_7'])
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        ml_data = df_sorted[features + ['total_sales_amount']].dropna()
        
        X = ml_data[features]
        y = ml_data['total_sales_amount']
        
        # Random Forest
        rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
        rf.fit(X, y)
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = pd.DataFrame({
            'feature': features,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("üèÜ –¢–û–ü-10 –§–ê–ö–¢–û–†–û–í –£–°–ü–ï–•–ê –ù–ê –†–´–ù–ö–ï:")
        for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):
            print(f"   {i+1}. {row['feature']}: {row['importance']:.3f} ({row['importance']*100:.1f}%)")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import r2_score, mean_absolute_error
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        rf.fit(X_train, y_train)
        y_pred = rf.predict(X_test)
        
        r2 = r2_score(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        print(f"\nüìä –ö–ê–ß–ï–°–¢–í–û –ú–û–î–ï–õ–ò:")
        print(f"   üéØ R¬≤ Score: {r2:.3f} ({r2*100:.1f}% –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏)")
        print(f"   üìè –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {mae:,.0f} IDR")
        
        return feature_importance
    else:
        print("‚ùå Scikit-learn –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞")
        return None

def analyze_seasonal_patterns():
    """–ê–Ω–∞–ª–∏–∑ —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ –≤—Å–µ–º—É —Ä—ã–Ω–∫—É"""
    print("\nüìÖ 4. –°–ï–ó–û–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´ –ò –¢–†–ï–ù–î–´")
    print("-" * 50)
    
    df = load_full_database()
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –º–µ—Å—è—Ü–∞–º
    monthly_stats = df.groupby('month').agg({
        'total_sales_amount': ['mean', 'sum'],
        'total_orders': ['mean', 'sum'],
        'rating': 'mean'
    }).round(2)
    
    monthly_stats.columns = ['avg_daily_sales', 'total_sales', 'avg_daily_orders', 'total_orders', 'avg_rating']
    
    print("üìä –ê–ù–ê–õ–ò–ó –ü–û –ú–ï–°–Ø–¶–ê–ú:")
    months = ['–Ø–Ω–≤', '–§–µ–≤', '–ú–∞—Ä', '–ê–ø—Ä', '–ú–∞–π', '–ò—é–Ω', '–ò—é–ª', '–ê–≤–≥', '–°–µ–Ω', '–û–∫—Ç', '–ù–æ—è', '–î–µ–∫']
    
    for month in range(1, 13):
        if month in monthly_stats.index:
            stats = monthly_stats.loc[month]
            print(f"   {months[month-1]}: {stats['avg_daily_sales']:,.0f} IDR/–¥–µ–Ω—å, ‚≠ê{stats['avg_rating']:.2f}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
    weekday_stats = df.groupby('day_of_week').agg({
        'total_sales_amount': 'mean',
        'total_orders': 'mean',
        'rating': 'mean'
    }).round(2)
    
    days = ['–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ', '–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–í—Ç–æ—Ä–Ω–∏–∫', '–°—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä–≥', '–ü—è—Ç–Ω–∏—Ü–∞', '–°—É–±–±–æ—Ç–∞']
    
    print(f"\nüìÖ –ê–ù–ê–õ–ò–ó –ü–û –î–ù–Ø–ú –ù–ï–î–ï–õ–ò:")
    for day in range(7):
        if day in weekday_stats.index:
            stats = weekday_stats.loc[day]
            print(f"   {days[day]}: {stats['total_sales_amount']:,.0f} IDR, {stats['total_orders']:.0f} –∑–∞–∫–∞–∑–æ–≤")
    
    # –í—ã—Ö–æ–¥–Ω—ã–µ vs –±—É–¥–Ω–∏
    weekend_comparison = df.groupby('is_weekend').agg({
        'total_sales_amount': 'mean',
        'total_orders': 'mean'
    }).round(2)
    
    if len(weekend_comparison) == 2:
        weekday_sales = weekend_comparison.loc[0, 'total_sales_amount']
        weekend_sales = weekend_comparison.loc[1, 'total_sales_amount']
        weekend_boost = ((weekend_sales - weekday_sales) / weekday_sales) * 100
        
        print(f"\nüéâ –≠–§–§–ï–ö–¢ –í–´–•–û–î–ù–´–•:")
        print(f"   üìà –†–æ—Å—Ç –ø—Ä–æ–¥–∞–∂ –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ: {weekend_boost:+.1f}%")
        print(f"   üí∞ –ë—É–¥–Ω–∏: {weekday_sales:,.0f} IDR")
        print(f"   üí∞ –í—ã—Ö–æ–¥–Ω—ã–µ: {weekend_sales:,.0f} IDR")

def platform_comparison_analysis():
    """–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–ª–∞—Ç—Ñ–æ—Ä–º Grab vs Gojek"""
    print("\nü•ä 5. GRAB VS GOJEK - –°–†–ê–í–ù–ï–ù–ò–ï –ü–õ–ê–¢–§–û–†–ú")
    print("-" * 50)
    
    df = load_full_database()
    
    platform_stats = df.groupby('platform').agg({
        'total_sales_amount': ['sum', 'mean', 'count'],
        'total_orders': ['sum', 'mean'],
        'rating': 'mean',
        'marketing_spend': 'sum',
        'avg_order_value': 'mean'
    }).round(2)
    
    platform_stats.columns = ['total_revenue', 'avg_daily_revenue', 'days_count',
                              'total_orders', 'avg_daily_orders', 'avg_rating',
                              'total_marketing', 'avg_order_value']
    
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –ü–õ–ê–¢–§–û–†–ú:")
    for platform in platform_stats.index:
        stats = platform_stats.loc[platform]
        print(f"\nüè™ {platform.upper()}:")
        print(f"   üí∞ –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞: {stats['total_revenue']:,.0f} IDR")
        print(f"   üì¶ –û–±—â–∏–µ –∑–∞–∫–∞–∑—ã: {stats['total_orders']:,.0f}")
        print(f"   ‚≠ê –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥: {stats['avg_rating']:.2f}")
        print(f"   üí≥ –°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {stats['avg_order_value']:,.0f} IDR")
        print(f"   üìÖ –î–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö: {stats['days_count']:,.0f}")
    
    # –†–∞—Å—á–µ—Ç –¥–æ–ª–∏ —Ä—ã–Ω–∫–∞
    if len(platform_stats) == 2:
        grab_revenue = platform_stats.loc['grab', 'total_revenue']
        gojek_revenue = platform_stats.loc['gojek', 'total_revenue']
        total_revenue = grab_revenue + gojek_revenue
        
        print(f"\nüìà –î–û–õ–Ø –†–´–ù–ö–ê:")
        print(f"   üü¢ Grab: {(grab_revenue/total_revenue)*100:.1f}%")
        print(f"   üîµ Gojek: {(gojek_revenue/total_revenue)*100:.1f}%")

def run_full_ml_analysis():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ ML –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    print("ü§ñ MUZAQUEST ANALYTICS - –ü–û–õ–ù–´–ô ML –ê–ù–ê–õ–ò–ó –í–°–ï–ô –ë–ê–ó–´")
    print("=" * 60)
    print("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º 25,129 –∑–∞–ø–∏—Å–µ–π –ø–æ 59 —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º (2023-2025)")
    print("=" * 60)
    
    try:
        # 1. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ä—ã–Ω–∫–∞
        restaurant_segments = analyze_market_segments()
        
        # 2. –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π
        market_anomalies = detect_market_anomalies()
        
        # 3. –§–∞–∫—Ç–æ—Ä—ã —É—Å–ø–µ—Ö–∞
        success_factors = analyze_success_factors()
        
        # 4. –°–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        analyze_seasonal_patterns()
        
        # 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º
        platform_comparison_analysis()
        
        print("\n" + "=" * 60)
        print("‚úÖ –ü–û–õ–ù–´–ô ML –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print("üéØ –í—Å–µ –∏–Ω—Å–∞–π—Ç—ã –ø–æ 59 —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º –ø–æ–ª—É—á–µ–Ω—ã")
        print("=" * 60)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ ML –∞–Ω–∞–ª–∏–∑–µ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run_full_ml_analysis()