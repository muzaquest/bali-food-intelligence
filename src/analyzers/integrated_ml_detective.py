#!/usr/bin/env python3
"""
ü§ñ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô ML + –î–ï–¢–ï–ö–¢–ò–í–ù–´–ô –ê–ù–ê–õ–ò–ó
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å ML –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å—é (SHAP)

‚úÖ –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:
- –î–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–Ω–µ–π
- ML –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–∞–∂  
- SHAP –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å –ø—Ä–∏—á–∏–Ω
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ML
"""

import sqlite3
import pandas as pd
import numpy as np
import json
import requests
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')
import os
import json
import joblib

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
try:
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import r2_score, mean_absolute_error
    import shap
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    print("‚ö†Ô∏è ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scikit-learn shap")

from .production_sales_analyzer import ProductionSalesAnalyzer

class IntegratedMLDetective:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ML + –¥–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä"""
    
    def __init__(self):
        # –î–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π)
        self.detective = ProductionSalesAnalyzer()
        
        # ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.ml_model = None
        self.shap_explainer = None
        self.feature_names = []
        self.model_trained = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ML –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if ML_AVAILABLE:
            self.ml_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            # Try load global model
            try:
                model_path = os.path.join('models', 'global_sales_rf.joblib')
                feats_path = os.path.join('models', 'global_sales_rf_features.json')
                if os.path.exists(model_path) and os.path.exists(feats_path):
                    self.ml_model = joblib.load(model_path)
                    with open(feats_path, 'r', encoding='utf-8') as f:
                        self.feature_names = json.load(f).get('features', [])
                    self.model_trained = True
            except Exception:
                pass
    
    def analyze_with_ml_explanations(self, restaurant_name, start_date, end_date):
        """
        –ì–õ–ê–í–ù–´–ô –ú–ï–¢–û–î: –¥–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ + ML –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        """
        print("ü§ñ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ ML + –¥–µ—Ç–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        
        # 1. –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ë–ï–ó ML (–∏–∑–±–µ–≥–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏–∏!)
        detective_results = self.detective._standard_detective_analysis(
            restaurant_name, start_date, end_date
        )
        
        if not ML_AVAILABLE:
            detective_results.append("")
            detective_results.append("‚ö†Ô∏è ML –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ scikit-learn –∏ shap")
            return detective_results
        
        # 2. –û–±—É—á–∞–µ–º ML –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—â–µ –Ω–µ –æ–±—É—á–µ–Ω–∞
        if not self.model_trained:
            print("üß† –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏...")
            self._train_ml_model(restaurant_name)
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º ML –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–Ω–µ–π
        ml_enhanced_results = []
        
        for i, result in enumerate(detective_results):
            ml_enhanced_results.append(result)
            
            # –ò—â–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–Ω–∏ –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞
            if "–ü–†–û–ë–õ–ï–ú–ù–´–ô –î–ï–ù–¨" in result and "2025-" in result:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏
                date_str = self._extract_date_from_result(result)
                if date_str:
                    print(f"üîç ML –∞–Ω–∞–ª–∏–∑ –¥–ª—è {date_str}...")
                    ml_explanation = self._get_ml_explanation_for_day(
                        restaurant_name, date_str
                    )
                    ml_enhanced_results.append("")
                    ml_enhanced_results.extend(ml_explanation)
                    
                    # What-if —Å—Ü–µ–Ω–∞—Ä–∏–∏
                    what_if = self._simulate_what_if_for_day(restaurant_name, date_str)
                    if what_if:
                        ml_enhanced_results.append("")
                        ml_enhanced_results.append("   üîÆ WHAT‚ÄëIF (–∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç—ã):")
                        ml_enhanced_results.extend([f"      ‚Ä¢ {line}" for line in what_if])
        
        # 4. –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é ML —Å–≤–æ–¥–∫—É
        ml_enhanced_results.append("")
        ml_enhanced_results.append("ü§ñ ML –°–í–û–î–ö–ê –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        ml_enhanced_results.append("=" * 50)
        ml_summary = self._generate_ml_summary(restaurant_name, start_date, end_date)
        ml_enhanced_results.extend(ml_summary)
        
        # 5. –ù–µ–¥–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–∏–±–æ–ª—å—à–µ–π –ø—Ä–æ—Å–∞–¥–∫–∏ (WoW) —Å SHAP —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏
        weekly = self._summarize_biggest_week_drop(restaurant_name, start_date, end_date)
        if weekly:
            ml_enhanced_results.append("")
            ml_enhanced_results.append("üìâ –ù–ï–î–ï–õ–¨–ù–´–ô –ü–†–û–°–ê–î–û–ß–ù–´–ô –ü–ï–†–ò–û–î (WoW):")
            ml_enhanced_results.append("-" * 50)
            ml_enhanced_results.extend(weekly)
        
        return ml_enhanced_results
    
    def _train_ml_model(self, restaurant_name):
        """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            training_data = self._prepare_training_data(restaurant_name)
            
            if len(training_data) < 10:
                print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏")
                return
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            features_df = training_data.drop(['sales', 'date'], axis=1)
            target = training_data['sales']
            
            self.feature_names = list(features_df.columns)
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç
            X_train, X_test, y_train, y_test = train_test_split(
                features_df, target, test_size=0.2, random_state=42
            )
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            self.ml_model.fit(X_train, y_train)
            
            # –°–æ–∑–¥–∞–µ–º SHAP –æ–±—ä—è—Å–Ω–∏—Ç–µ–ª—å
            self.shap_explainer = shap.TreeExplainer(self.ml_model)
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            y_pred = self.ml_model.predict(X_test)
            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            
            print(f"‚úÖ ML –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: R¬≤ = {r2:.3f}, MAE = {mae:,.0f} IDR")
            self.model_trained = True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏: {e}")
            self.model_trained = False
    
    def _prepare_training_data(self, restaurant_name):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏"""
        
        conn = sqlite3.connect('database.sqlite')
        
        # –ü–æ–ª—É—á–∞–µ–º ID —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞
        restaurant_query = f"SELECT id FROM restaurants WHERE name = '{restaurant_name}'"
        restaurant_df = pd.read_sql_query(restaurant_query, conn)
        
        if restaurant_df.empty:
            return pd.DataFrame()
        
        restaurant_id = restaurant_df.iloc[0]['id']
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 –º–µ—Å—è—Ü–µ–≤
        query = f"""
        WITH all_dates AS (
            SELECT stat_date FROM grab_stats 
            WHERE restaurant_id = {restaurant_id}
            AND stat_date >= date('now', '-6 months')
            UNION
            SELECT stat_date FROM gojek_stats 
            WHERE restaurant_id = {restaurant_id}
            AND stat_date >= date('now', '-6 months')
        )
        SELECT 
            ad.stat_date as date,
            COALESCE(g.sales, 0) + COALESCE(gj.sales, 0) as sales,
            
            -- –í–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            CASE WHEN strftime('%w', ad.stat_date) IN ('0', '6') THEN 1 ELSE 0 END as is_weekend,
            CAST(strftime('%w', ad.stat_date) AS INTEGER) as day_of_week,
            
            -- –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã  
            COALESCE(g.offline_rate, 0) as grab_offline_rate,
            CASE WHEN gj.close_time IS NOT NULL AND gj.close_time != '00:00:00' THEN 1 ELSE 0 END as gojek_closed,
            
            -- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–≤ –º–∏–Ω—É—Ç–∞—Ö)
            CASE WHEN gj.preparation_time IS NOT NULL AND gj.preparation_time != '00:00:00'
                THEN (CAST(substr(gj.preparation_time, 1, 2) AS INTEGER) * 60 + 
                      CAST(substr(gj.preparation_time, 4, 2) AS INTEGER))
                ELSE 15 END as preparation_minutes,
                
            CASE WHEN gj.delivery_time IS NOT NULL AND gj.delivery_time != '00:00:00'
                THEN (CAST(substr(gj.delivery_time, 1, 2) AS INTEGER) * 60 + 
                      CAST(substr(gj.delivery_time, 7, 2) AS INTEGER))
                ELSE 20 END as delivery_minutes,
            
            -- –ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            COALESCE(g.ads_spend, 0) + COALESCE(gj.ads_spend, 0) as total_ads_spend,
            COALESCE(g.impressions, 0) as impressions,
            
            -- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            COALESCE(g.rating, gj.rating, 4.5) as rating,
            COALESCE(g.orders, 0) + COALESCE(gj.orders, 0) as total_orders
            
        FROM all_dates ad
        LEFT JOIN grab_stats g ON ad.stat_date = g.stat_date AND g.restaurant_id = {restaurant_id}
        LEFT JOIN gojek_stats gj ON ad.stat_date = gj.stat_date AND gj.restaurant_id = {restaurant_id}
        ORDER BY ad.stat_date
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        if df.empty:
            return df
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
        df['is_holiday'] = df['date'].apply(self._check_holiday)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
        df['precipitation'] = 0  # –ë—É–¥–µ–º –ø–æ–ª—É—á–∞—Ç—å –∏–∑ API –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
        df['temperature'] = 27   # –°—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –ë–∞–ª–∏
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ (–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ)
        df['sales_7day_avg'] = df['sales'].rolling(window=7, min_periods=1).mean().shift(1)
        df['sales_30day_avg'] = df['sales'].rolling(window=30, min_periods=1).mean().shift(1)
        
        # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN
        df = df.dropna()
        
        return df
    
    def _get_ml_explanation_for_day(self, restaurant_name, target_date):
        """–ü–æ–ª—É—á–∞–µ—Ç ML –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–Ω—è"""
        
        if not self.model_trained:
            return ["‚ö†Ô∏è ML –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"]
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –¥–Ω—è
            features = self._prepare_features_for_date(restaurant_name, target_date)
            
            if not features:
                return ["‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞"]
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏
            actual_sales = self._get_actual_sales(restaurant_name, target_date)
            
            # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
            feature_array = np.array([list(features.values())])
            predicted_sales = self.ml_model.predict(feature_array)[0]
            
            # –ü–æ–ª—É—á–∞–µ–º SHAP –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            shap_values = self.shap_explainer.shap_values(feature_array)[0]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            explanation = []
            explanation.append("üß† ML –û–ë–™–Ø–°–ù–ï–ù–ò–ï (SHAP):")
            explanation.append(f"   üí∞ –†–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏: {actual_sales:,.0f} IDR")
            explanation.append(f"   ü§ñ ML –ø—Ä–æ–≥–Ω–æ–∑: {predicted_sales:,.0f} IDR")
            
            deviation_pct = ((actual_sales - predicted_sales) / predicted_sales) * 100 if predicted_sales else 0
            explanation.append(f"   üìä –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation_pct:+.1f}%")
            explanation.append("")
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            feature_importance = list(zip(self.feature_names, features.values(), shap_values))
            feature_importance.sort(key=lambda x: abs(x[2]), reverse=True)
            
            explanation.append("   üîç –ì–õ–ê–í–ù–´–ï –§–ê–ö–¢–û–†–´ –í–õ–ò–Ø–ù–ò–Ø:")
            
            shown = 0
            for i, (feature_name, feature_value, shap_value) in enumerate(feature_importance):
                if abs(shap_value) < 50000:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –º–∞–ª–æ–∑–Ω–∞—á–∏–º—ã–µ
                    continue
                impact_pct = (shap_value / predicted_sales) * 100 if predicted_sales else 0
                formatted_name = self._format_feature_name(feature_name)
                if shap_value > 0:
                    explanation.append(f"      {i+1}. ‚úÖ {formatted_name}: +{impact_pct:.1f}% –≤–ª–∏—è–Ω–∏—è (+{shap_value:,.0f} IDR)")
                else:
                    explanation.append(f"      {i+1}. üö® {formatted_name}: {impact_pct:.1f}% –≤–ª–∏—è–Ω–∏—è ({shap_value:,.0f} IDR)")
                shown += 1
                if shown >= 5:
                    break
            
            # –î–æ–±–∞–≤–ª—è–µ–º ML —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            explanation.append("")
            explanation.append("   üí° ML –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            ml_recommendations = self._generate_ml_recommendations(feature_importance, predicted_sales)
            explanation.extend([f"      ‚Ä¢ {rec}" for rec in ml_recommendations])
            
            return explanation
            
        except Exception as e:
            return [f"‚ùå –û—à–∏–±–∫–∞ ML –∞–Ω–∞–ª–∏–∑–∞: {e}"]
    
    def _simulate_what_if_for_day(self, restaurant_name: str, target_date: str):
        """–ü—Ä–æ—Å—Ç—ã–µ –∫–æ–Ω—Ç—Ä—Ñ–∞–∫—Ç—ã: –±–µ–∑ –¥–æ–∂–¥—è, +20% —Ä–µ–∫–ª–∞–º–∞, –±–µ–∑ –ø—Ä–æ—Å—Ç–æ–µ–≤ –ø–ª–∞—Ç—Ñ–æ—Ä–º."""
        try:
            if not self.model_trained:
                return []
            base_feats = self._prepare_features_for_date(restaurant_name, target_date)
            if not base_feats:
                return []
            actual = self._get_actual_sales(restaurant_name, target_date)
            base_pred = float(self.ml_model.predict(np.array([list(base_feats.values())]))[0])
            scenarios = []
            # 1) –ë–µ–∑ –¥–æ–∂–¥—è
            f1 = dict(base_feats); f1['precipitation'] = 0.0
            pred1 = float(self.ml_model.predict(np.array([list(f1.values())]))[0])
            scenarios.append(("–ë–µ–∑ –¥–æ–∂–¥—è", pred1 - actual))
            # 2) +20% —Ä–µ–∫–ª–∞–º—ã
            f2 = dict(base_feats); f2['total_ads_spend'] = base_feats.get('total_ads_spend', 0.0) * 1.2
            pred2 = float(self.ml_model.predict(np.array([list(f2.values())]))[0])
            scenarios.append(("+20% —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –±—é–¥–∂–µ—Ç–∞", pred2 - actual))
            # 3) –ë–µ–∑ –ø—Ä–æ—Å—Ç–æ–µ–≤ (–æ–±–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã —Å—Ç–∞–±–∏–ª—å–Ω–æ)
            f3 = dict(base_feats); f3['grab_offline_rate'] = 0.0; f3['gojek_closed'] = 0
            pred3 = float(self.ml_model.predict(np.array([list(f3.values())]))[0])
            scenarios.append(("–ë–µ–∑ –ø—Ä–æ—Å—Ç–æ–µ–≤ –ø–ª–∞—Ç—Ñ–æ—Ä–º", pred3 - actual))
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
            lines = [f"{name}: +{delta:,.0f} IDR" if delta>0 else f"{name}: {delta:,.0f} IDR" for name, delta in scenarios]
            return lines
        except Exception:
            return []
    
    def _prepare_features_for_date(self, restaurant_name, target_date):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¥–∞—Ç—ã"""
        
        conn = sqlite3.connect('database.sqlite')
        
        # –ü–æ–ª—É—á–∞–µ–º ID —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞
        restaurant_query = f"SELECT id FROM restaurants WHERE name = '{restaurant_name}'"
        restaurant_df = pd.read_sql_query(restaurant_query, conn)
        
        if restaurant_df.empty:
            return {}
        
        restaurant_id = restaurant_df.iloc[0]['id']
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ —Ü–µ–ª–µ–≤—É—é –¥–∞—Ç—É
        query = f"""
        SELECT 
            g.offline_rate,
            gj.close_time,
            gj.preparation_time,
            gj.delivery_time,
            g.ads_spend as grab_ads_spend,
            gj.ads_spend as gojek_ads_spend,
            g.impressions as grab_impressions,
            COALESCE(g.rating, 0) as rating_grab,
            COALESCE(gj.rating, 0) as rating_gojek,
            (COALESCE(g.orders, 0) + COALESCE(gj.orders, 0)) as total_orders,
            (COALESCE(g.sales, 0) + COALESCE(gj.sales, 0)) as total_sales
        FROM grab_stats g
        LEFT JOIN gojek_stats gj ON g.restaurant_id = gj.restaurant_id 
                                   AND g.stat_date = gj.stat_date
        WHERE g.restaurant_id = {restaurant_id} AND g.stat_date = '{target_date}'
        """
        
        df = pd.read_sql_query(query, conn)
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è rolling –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        hist_q = f"""
        WITH all_dates AS (
            SELECT stat_date d, COALESCE(sales,0) s FROM grab_stats WHERE restaurant_id={restaurant_id}
            UNION ALL
            SELECT stat_date d, COALESCE(sales,0) s FROM gojek_stats WHERE restaurant_id={restaurant_id}
        )
        SELECT d as date, SUM(s) total FROM all_dates GROUP BY d ORDER BY d
        """
        hist = pd.read_sql_query(hist_q, conn)
        conn.close()
        
        if df.empty:
            return {}
        
        row = df.iloc[0]
        
        # –î–∞—Ç–∞
        date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        
        # Rolling –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞
        sales_7day_avg = 0.0
        sales_30day_avg = 0.0
        sales_gradient_7 = 0.0
        if not hist.empty:
            hist['date'] = pd.to_datetime(hist['date'])
            hist = hist.sort_values('date')
            hist['total'] = pd.to_numeric(hist['total'], errors='coerce').fillna(0)
            hist.set_index('date', inplace=True)
            if date_obj in hist.index:
                # —Å–¥–≤–∏–≥ –Ω–∞ 1 –¥–µ–Ω—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª–æ–µ
                before = hist.loc[:date_obj - pd.Timedelta(days=1)]['total']
            else:
                before = hist.loc[:date_obj]['total']
            if not before.empty:
                sales_7day_avg = before.rolling(window=7, min_periods=1).mean().iloc[-1]
                sales_30day_avg = before.rolling(window=30, min_periods=1).mean().iloc[-1]
                if len(before) >= 7:
                    sales_gradient_7 = before.iloc[-1] - before.iloc[-7]
        
        # –ü—Ä–∞–∑–¥–Ω–∏–∫–∏
        is_holiday = 1 if self._check_holiday(target_date) else 0
        
        # –ü–æ–≥–æ–¥–∞ (–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Ç–æ–¥–∞)
        weather_data = self.detective._get_weather_data(restaurant_name, target_date)
        precipitation = weather_data['precipitation'] if weather_data else 0.0
        temperature = weather_data['temperature'] if weather_data else 27.0
        
        # –¢—É—Ä–∏–∑–º
        tourism_index = 0.0
        try:
            from src.utils.tourism_loader import load_tourism_index
            tourism_map = load_tourism_index()
            tourism_index = float(tourism_map.get(target_date, 0.0))
        except Exception:
            pass
        
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω –∫ –º–∏–Ω—É—Ç–∞–º
        def to_min(x):
            if not x or x in ['00:00:00','0:0:0','0:00:00','00:0:0']:
                return 0.0
            try:
                h,m,s = map(int, str(x).split(':'))
                return h*60 + m + s/60.0
            except Exception:
                return 0.0
        
        features = {
            'grab_offline_rate': float(row['offline_rate'] or 0),
            'gojek_close_minutes': to_min(row['close_time']) if pd.notna(row['close_time']) else 0.0,
            'gojek_preparation_minutes': to_min(row['preparation_time']) if pd.notna(row['preparation_time']) else 0.0,
            'gojek_delivery_minutes': to_min(row['delivery_time']) if pd.notna(row['delivery_time']) else 0.0,
            'grab_driver_waiting': 0.0,  # –Ω–µ—Ç –ø—Ä—è–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ gojek/grab –¥–ª—è –¥–Ω—è
            'gojek_driver_waiting': 0.0,
            'ads_spend_total': float(row['grab_ads_spend'] or 0) + float(row['gojek_ads_spend'] or 0),
            'impressions_total': float(row['grab_impressions'] or 0),
            'rating_grab': float(row['rating_grab'] or 0),
            'rating_gojek': float(row['rating_gojek'] or 0),
            'is_weekend': 1 if date_obj.weekday() >= 5 else 0,
            'day_of_week': date_obj.weekday(),
            'is_holiday': is_holiday,
            'precipitation': precipitation,
            'temperature': temperature,
            'sales_7day_avg': float(sales_7day_avg or 0.0),
            'sales_30day_avg': float(sales_30day_avg or 0.0),
            'sales_gradient_7': float(sales_gradient_7 or 0.0),
            'tourism_index': float(tourism_index or 0.0),
        }
        
        return features
    
    def _get_historical_features(self, restaurant_name, target_date):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ)"""
        
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª –±—ã –∑–∞–ø—Ä–æ—Å –∫ –ë–î
        return {
            'sales_7day_avg': 5000000,  # 5M IDR —Å—Ä–µ–¥–Ω–∏–µ –∑–∞ –Ω–µ–¥–µ–ª—é
            'sales_30day_avg': 6000000  # 6M IDR —Å—Ä–µ–¥–Ω–∏–µ –∑–∞ –º–µ—Å—è—Ü
        }
    
    def _time_to_minutes(self, time_str):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è HH:MM:SS –≤ –º–∏–Ω—É—Ç—ã"""
        if not time_str or time_str in ['00:00:00', '0:0:0', '0:00:00', '00:0:0']:
            return 0
        
        try:
            parts = time_str.split(':')
            hours = int(parts[0]) if parts[0] else 0
            minutes = int(parts[1]) if len(parts) > 1 and parts[1] else 0
            return hours * 60 + minutes
        except:
            return 0
    
    def _get_actual_sales(self, restaurant_name, target_date):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ –¥–µ–Ω—å"""
        
        day_data = self.detective._get_day_data(restaurant_name, target_date)
        if day_data:
            return day_data.get('total_sales', 0)
        return 0
    
    def _check_holiday(self, date_str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–µ–Ω—å –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–º"""
        return date_str in self.detective.holidays_data
    
    def _format_feature_name(self, feature_name):
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
        
        name_mapping = {
            'grab_offline_rate': 'üì± Grab offline rate',
            'gojek_closed': 'üõµ Gojek –∑–∞–∫—Ä—ã—Ç',
            'preparation_minutes': '‚è±Ô∏è –í—Ä–µ–º—è –≥–æ—Ç–æ–≤–∫–∏',
            'delivery_minutes': 'üöö –í—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏',
            'total_ads_spend': 'üí∞ –†–∞—Å—Ö–æ–¥—ã –Ω–∞ —Ä–µ–∫–ª–∞–º—É',
            'is_holiday': 'üéâ –ü—Ä–∞–∑–¥–Ω–∏–∫',
            'is_weekend': 'üìÖ –í—ã—Ö–æ–¥–Ω–æ–π',
            'rating': '‚≠ê –†–µ–π—Ç–∏–Ω–≥',
            'precipitation': 'üåßÔ∏è –û—Å–∞–¥–∫–∏ (–º–º)',
            'temperature': 'üå°Ô∏è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (¬∞C)',
            'sales_7day_avg': 'üìà –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏ (7 –¥–Ω–µ–π)',
            'sales_30day_avg': 'üìà –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏ (30 –¥–Ω–µ–π)'
        }
        
        return name_mapping.get(feature_name, feature_name)
    
    def _generate_ml_recommendations(self, feature_importance, predicted_sales):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ ML –∞–Ω–∞–ª–∏–∑–∞"""
        
        recommendations = []
        
        for feature_name, feature_value, shap_value in feature_importance[:3]:
            if abs(shap_value) < 100000:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –º–∞–ª–æ–∑–Ω–∞—á–∏–º—ã–µ
                continue
                
            impact_idr = abs(shap_value)
            
            if feature_name == 'grab_offline_rate' and shap_value < 0:
                recommendations.append(f"–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è Grab = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
            elif feature_name in ['preparation_minutes', 'delivery_minutes'] and shap_value < 0:
                recommendations.append(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
            elif feature_name == 'precipitation' and shap_value < 0:
                recommendations.append(f"–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –¥–æ–∂–¥—å = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
            elif feature_name == 'is_holiday' and shap_value < 0:
                recommendations.append(f"–£—á–µ—Ç –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
            elif feature_name == 'total_ads_spend' and shap_value > 0:
                recommendations.append(f"–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–∫–ª–∞–º—ã = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
            elif feature_name == 'rating' and shap_value < 0:
                recommendations.append(f"–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª +{impact_idr:,.0f} IDR")
        
        if not recommendations:
            recommendations.append("–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ")
        
        return recommendations
    
    def _generate_ml_summary(self, restaurant_name, start_date, end_date):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—â—É—é ML —Å–≤–æ–¥–∫—É"""
        
        summary = []
        
        if self.model_trained:
            # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏
            feature_importances = list(zip(self.feature_names, self.ml_model.feature_importances_))
            feature_importances.sort(key=lambda x: x[1], reverse=True)
            
            summary.append("üèÜ –ì–õ–ê–í–ù–´–ï –î–†–ê–ô–í–ï–†–´ –ü–†–û–î–ê–ñ (–≤–∞–∂–Ω–æ—Å—Ç—å –≤ ML –º–æ–¥–µ–ª–∏):")
            
            for i, (feature_name, importance) in enumerate(feature_importances[:5]):
                formatted_name = self._format_feature_name(feature_name)
                summary.append(f"   {i+1}. {formatted_name}: {importance*100:.1f}% –≤–∞–∂–Ω–æ—Å—Ç–∏")
            
            summary.append("")
            summary.append("üí° –û–ë–©–ò–ï ML –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            summary.append("   1. üö® –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–ª–∞—Ç—Ñ–æ—Ä–º - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ñ–∞–∫—Ç–æ—Ä")
            summary.append("   2. ‚è±Ô∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω")
            summary.append("   3. üå§Ô∏è –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –ø–æ–≥–æ–¥–Ω—ã–µ —É—Å–ª–æ–≤–∏—è")
            summary.append("   4. üéâ –£—á–µ—Ç –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏")
            summary.append("   5. üí∞ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Ä–µ–∫–ª–∞–º–Ω—ã—Ö –±—é–¥–∂–µ—Ç–æ–≤")
            summary.append("   6. ‚≠ê –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è")
        else:
            summary.append("‚ö†Ô∏è ML –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ - –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
        
        return summary
    
    def _summarize_biggest_week_drop(self, restaurant_name: str, start_date: str, end_date: str):
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª—å—à—É—é –Ω–µ–¥–µ–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É (WoW) –∏ —Å—É–º–º–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ SHAP‚Äë—Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ–¥–µ–ª–∏."""
        try:
            with sqlite3.connect('database.sqlite') as conn:
                # –°—É–º–º–∞ –ø—Ä–æ–¥–∞–∂ –ø–æ –¥–Ω—è–º –≤ –ø–µ—Ä–∏–æ–¥–µ
                q = f"""
                WITH all_dates AS (
                    SELECT stat_date d, COALESCE(sales,0) s FROM grab_stats WHERE restaurant_id=(SELECT id FROM restaurants WHERE name='{restaurant_name}') AND stat_date BETWEEN '{start_date}' AND '{end_date}'
                    UNION ALL
                    SELECT stat_date d, COALESCE(sales,0) s FROM gojek_stats WHERE restaurant_id=(SELECT id FROM restaurants WHERE name='{restaurant_name}') AND stat_date BETWEEN '{start_date}' AND '{end_date}'
                )
                SELECT d as date, SUM(s) total FROM all_dates GROUP BY d ORDER BY d
                """
                df = pd.read_sql_query(q, conn)
            if df.empty:
                return []
            df['date'] = pd.to_datetime(df['date'])
            df['week'] = df['date'].dt.isocalendar().week
            wk = df.groupby('week', as_index=False)['total'].sum().sort_values('week')
            wk['prev'] = wk['total'].shift(1)
            wk['wow'] = (wk['total'] - wk['prev'])/wk['prev']*100.0
            wk = wk.dropna(subset=['wow'])
            if wk.empty:
                return []
            worst_week = wk.loc[wk['wow'].idxmin()]
            target_week = int(worst_week['week'])
            change = float(worst_week['wow'])
            # –î–∞—Ç—ã –≤—ã–±—Ä–∞–Ω–Ω–æ–π –Ω–µ–¥–µ–ª–∏
            dates = df[df['week']==target_week]['date'].dt.strftime('%Y-%m-%d').tolist()
            # SHAP —Å—É–º–º—ã –ø–æ –Ω–µ–¥–µ–ª–µ (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            if not self.model_trained:
                return [f"–ù–µ–¥–µ–ª—è #{target_week}: {change:.1f}% vs –ø—Ä–µ–¥. –Ω–µ–¥–µ–ª—è (ML –Ω–µ –æ–±—É—á–µ–Ω)"]
            agg = {}
            for d in dates:
                feats = self._prepare_features_for_date(restaurant_name, d)
                if not feats:
                    continue
                arr = np.array([list(feats.values())])
                shap_vals = self.shap_explainer.shap_values(arr)[0]
                for name, val in zip(self.feature_names, shap_vals):
                    agg[name] = agg.get(name, 0.0) + abs(float(val))
            if not agg:
                return [f"–ù–µ–¥–µ–ª—è #{target_week}: {change:.1f}% vs –ø—Ä–µ–¥. –Ω–µ–¥–µ–ª—è"]
            top = sorted([(k,v) for k,v in agg.items()], key=lambda x: x[1], reverse=True)[:5]
            lines = [f"–ù–µ–¥–µ–ª—è #{target_week}: {change:.1f}% vs –ø—Ä–µ–¥. –Ω–µ–¥–µ–ª—è"]
            lines.append("–¢–æ–ø‚Äë—Ñ–∞–∫—Ç–æ—Ä—ã –Ω–µ–¥–µ–ª–∏:")
            for name, val in top:
                lines.append(f"‚Ä¢ {self._format_feature_name(name)}")
            return lines
        except Exception:
            return []
    
    def _extract_date_from_result(self, result_line):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        
        import re
        date_pattern = r'(2025-\d{2}-\d{2})'
        match = re.search(date_pattern, result_line)
        return match.group(1) if match else None


# –ö–ª–∞—Å—Å-–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å main.py
class ProperMLDetectiveAnalysis:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º"""
    
    def __init__(self):
        self.integrated = IntegratedMLDetective()
    
    def run_ml_detective_analysis(self, restaurant_name, start_date=None, end_date=None):
        """–ú–µ—Ç–æ–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å main.py"""
        
        if not start_date:
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d')
        
        return self.integrated.analyze_with_ml_explanations(
            restaurant_name, start_date, end_date
        )