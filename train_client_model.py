#!/usr/bin/env python3
"""
–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import sqlite3
import joblib
import os
from datetime import datetime, timedelta

def load_client_data(db_path='client_data.db'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ SQLite"""
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–∞...")
    
    conn = sqlite3.connect(db_path)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–∂
    query = """
    SELECT 
        g.restaurant_id,
        g.date,
        g.sales,
        g.orders,
        g.avg_order_value,
        g.ads_enabled,
        g.rating,
        g.delivery_time,
        r.name as restaurant_name,
        r.region
    FROM grab_stats g
    LEFT JOIN restaurants r ON g.restaurant_id = r.id
    ORDER BY g.restaurant_id, g.date
    """
    
    df = pd.read_sql_query(query, conn)
    conn.close()
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
    print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {df['date'].min()} - {df['date'].max()}")
    print(f"üè™ –†–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤: {df['restaurant_id'].nunique()}")
    
    return df

def create_features(df):
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
    print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
    df['date'] = pd.to_datetime(df['date'])
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['day_of_week'] = df['date'].dt.dayofweek
    df['week_of_year'] = df['date'].dt.isocalendar().week
    
    # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['is_high_season'] = df['month'].isin([6, 7, 8]).astype(int)  # –í—ã—Å–æ–∫–∏–π —Å–µ–∑–æ–Ω
    df['is_low_season'] = df['month'].isin([3, 4, 5, 9, 10]).astype(int)  # –ù–∏–∑–∫–∏–π —Å–µ–∑–æ–Ω
    
    # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø—Ä–æ–¥–∞–∂–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–Ω–µ–π)
    df = df.sort_values(['restaurant_id', 'date'])
    for lag in [1, 2, 3, 7]:
        df[f'sales_lag_{lag}'] = df.groupby('restaurant_id')['sales'].shift(lag)
    
    # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
    for window in [3, 7, 14]:
        df[f'sales_ma_{window}'] = df.groupby('restaurant_id')['sales'].rolling(window=window, min_periods=1).mean().reset_index(0, drop=True)
    
    # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    df['sales_change_1d'] = df.groupby('restaurant_id')['sales'].pct_change()
    df['sales_change_7d'] = df.groupby('restaurant_id')['sales'].pct_change(periods=7)
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df['region_encoded'] = pd.Categorical(df['region']).codes
    df['restaurant_encoded'] = pd.Categorical(df['restaurant_name']).codes
    
    # –ë–∏–∑–Ω–µ—Å-–ø—Ä–∏–∑–Ω–∞–∫–∏
    df['ads_enabled'] = df['ads_enabled'].astype(int)
    df['rating_normalized'] = (df['rating'] - df['rating'].mean()) / df['rating'].std()
    df['delivery_time_normalized'] = (df['delivery_time'] - df['delivery_time'].mean()) / df['delivery_time'].std()
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    return df

def prepare_ml_data(df):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML"""
    print("üéØ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML...")
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏ (–±–µ–∑ –ª–∞–≥–æ–≤—ã—Ö –¥–ª—è –Ω–∞—á–∞–ª–∞)
    feature_columns = [
        'year', 'month', 'day', 'day_of_week', 'week_of_year',
        'is_weekend', 'is_high_season', 'is_low_season',
        'region_encoded', 'restaurant_encoded',
        'orders', 'avg_order_value', 'ads_enabled',
        'rating_normalized', 'delivery_time_normalized'
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –∏ –Ω–µ –≤—Å–µ NaN
    lag_features = ['sales_lag_1', 'sales_lag_2', 'sales_lag_3', 'sales_lag_7']
    ma_features = ['sales_ma_3', 'sales_ma_7', 'sales_ma_14']
    change_features = ['sales_change_1d', 'sales_change_7d']
    
    for feature_group in [lag_features, ma_features, change_features]:
        for feature in feature_group:
            if feature in df.columns and not df[feature].isna().all():
                feature_columns.append(feature)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    available_features = [col for col in feature_columns if col in df.columns]
    print(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(available_features)} –∏–∑ {len(feature_columns)}")
    
    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –µ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    df_clean = df.dropna(subset=['sales', 'orders', 'region_encoded', 'restaurant_encoded'])
    
    X = df_clean[available_features]
    y = df_clean['sales']
    
    # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –Ω—É–ª—è–º–∏ –¥–ª—è –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X = X.fillna(0)
    
    # –£–±–∏—Ä–∞–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    X = X.replace([np.inf, -np.inf], 0)
    
    print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(X)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    print(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–∏: {available_features}")
    
    return X, y, available_features

def train_model(X, y, feature_names):
    """–û–±—É—á–∞–µ—Ç ML –º–æ–¥–µ–ª—å"""
    print("ü§ñ –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏...")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=True
    )
    
    print(f"üìä –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"üìä –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=15,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    
    print("üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model.fit(X_train, y_train)
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    
    train_r2 = r2_score(y_train, train_pred)
    test_r2 = r2_score(y_test, test_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
    
    print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø:")
    print(f"üéØ R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_r2:.4f}")
    print(f"üéØ R¬≤ –Ω–∞ —Ç–µ—Å—Ç–µ: {test_r2:.4f}")
    print(f"üìä RMSE –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_rmse:,.0f}")
    print(f"üìä RMSE –Ω–∞ —Ç–µ—Å—Ç–µ: {test_rmse:,.0f}")
    
    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüîù –¢–û–ü-10 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
    for i, row in feature_importance.head(10).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
    
    return model, feature_importance, {
        'train_r2': train_r2,
        'test_r2': test_r2,
        'train_rmse': train_rmse,
        'test_rmse': test_rmse
    }

def save_model(model, feature_names, feature_importance, metrics):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ"""
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –º–æ–¥–µ–ª–µ–π
    os.makedirs('models', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    model_path = 'models/client_sales_model.joblib'
    joblib.dump(model, model_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        'model_type': 'RandomForestRegressor',
        'feature_names': feature_names,
        'feature_importance': feature_importance.to_dict('records'),
        'metrics': metrics,
        'trained_at': datetime.now().isoformat(),
        'model_path': model_path
    }
    
    metadata_path = 'models/client_model_metadata.json'
    import json
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2, default=str)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
    print(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
    
    return model_path, metadata_path

def main():
    print("üöÄ –û–ë–£–ß–ï–ù–ò–ï ML –ú–û–î–ï–õ–ò –ù–ê –î–ê–ù–ù–´–• –ö–õ–ò–ï–ù–¢–ê")
    print("=" * 60)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = load_client_data()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_with_features = create_features(df)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–ª—è ML
        X, y, feature_names = prepare_ml_data(df_with_features)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model, feature_importance, metrics = train_model(X, y, feature_names)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_path, metadata_path = save_model(model, feature_names, feature_importance, metrics)
        
        print("\nüéâ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û!")
        print("=" * 60)
        print("üìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å: python3 test_client_model.py")
        print("2. –°–æ–∑–¥–∞–π—Ç–µ –æ—Ç—á–µ—Ç—ã: python3 generate_client_reports.py")
        print("3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ —Å –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º–æ–π")
        
        if metrics['test_r2'] > 0.7:
            print(f"\n‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏! R¬≤ = {metrics['test_r2']:.3f}")
        elif metrics['test_r2'] > 0.5:
            print(f"\n‚ö†Ô∏è –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏. R¬≤ = {metrics['test_r2']:.3f}")
        else:
            print(f"\n‚ùå –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è. R¬≤ = {metrics['test_r2']:.3f}")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()