#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–ê–°–®–¢–ê–ë–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û–ì–û–î–ù–´–• –ó–ê–ö–û–ù–û–ú–ï–†–ù–û–°–¢–ï–ô
========================================

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è
—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–¶–ï–õ–¨: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å 10,000+ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤
"""

import sqlite3
import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from collections import defaultdict
import requests
import os
from scipy import stats
import time
import warnings
warnings.filterwarnings('ignore')

class LargeScaleWeatherAnalyzer:
    def __init__(self):
        self.db_path = 'database.sqlite'
        self.locations_file = 'data/bali_restaurant_locations.json'
        self.weather_api_url = "https://api.open-meteo.com/v1/forecast"
        self.cache_file = 'data/large_scale_weather_cache.json'
        self.results_file = 'data/large_scale_analysis_results.json'
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.weather_cache = self._load_cache()
        
    def _load_cache(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫—ç—à –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    
    def _save_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            os.makedirs('data', exist_ok=True)
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.weather_cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")
    
    def get_large_sample_data(self, sample_size=10000):
        """–ü–æ–ª—É—á–∞–µ—Ç –±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ"""
        conn = sqlite3.connect(self.db_path)
        
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        strat_query = """
        SELECT 
            r.name as restaurant_name,
            COUNT(*) as record_count
        FROM restaurants r
        LEFT JOIN grab_stats g ON r.id = g.restaurant_id 
        LEFT JOIN gojek_stats gj ON r.id = gj.restaurant_id 
        WHERE (g.stat_date IS NOT NULL OR gj.stat_date IS NOT NULL)
          AND (COALESCE(g.sales, 0) + COALESCE(gj.sales, 0)) > 0
        GROUP BY r.name
        ORDER BY record_count DESC
        """
        
        restaurant_stats = pd.read_sql_query(strat_query, conn)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        top_restaurants = restaurant_stats.head(20)['restaurant_name'].tolist()
        
        print(f"üìä –í—ã–±—Ä–∞–Ω–æ {len(top_restaurants)} —Ç–æ–ø-—Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞–º
        records_per_restaurant = sample_size // len(top_restaurants)
        
        all_data = []
        
        for restaurant in top_restaurants:
            query = f"""
            SELECT 
                r.name as restaurant_name,
                COALESCE(g.stat_date, gj.stat_date) as date,
                COALESCE(g.sales, 0) + COALESCE(gj.sales, 0) as total_sales,
                COALESCE(g.orders, 0) + COALESCE(gj.orders, 0) as total_orders,
                g.cancelled_orders as grab_cancelled,
                g.store_is_busy as grab_busy,
                g.store_is_closed as grab_closed,
                g.out_of_stock as grab_out_of_stock,
                CASE 
                    WHEN (COALESCE(g.orders, 0) + COALESCE(gj.orders, 0)) > 0 
                    THEN (COALESCE(g.sales, 0) + COALESCE(gj.sales, 0)) / (COALESCE(g.orders, 0) + COALESCE(gj.orders, 0))
                    ELSE 0 
                END as avg_order_value,
                CASE CAST(strftime('%w', COALESCE(g.stat_date, gj.stat_date)) AS INTEGER)
                    WHEN 0 THEN 'Sunday'
                    WHEN 1 THEN 'Monday'
                    WHEN 2 THEN 'Tuesday'
                    WHEN 3 THEN 'Wednesday'
                    WHEN 4 THEN 'Thursday'
                    WHEN 5 THEN 'Friday'
                    WHEN 6 THEN 'Saturday'
                END as day_of_week
            FROM restaurants r
            LEFT JOIN grab_stats g ON r.id = g.restaurant_id 
            LEFT JOIN gojek_stats gj ON r.id = gj.restaurant_id 
            WHERE r.name = '{restaurant}'
              AND (g.stat_date IS NOT NULL OR gj.stat_date IS NOT NULL)
              AND (COALESCE(g.sales, 0) + COALESCE(gj.sales, 0)) > 0
            ORDER BY RANDOM()
            LIMIT {records_per_restaurant}
            """
            
            restaurant_data = pd.read_sql_query(query, conn)
            all_data.append(restaurant_data)
            
            print(f"   ‚úÖ {restaurant}: {len(restaurant_data)} –∑–∞–ø–∏—Å–µ–π")
        
        conn.close()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        final_data = pd.concat(all_data, ignore_index=True)
        
        print(f"\nüìä –ò–¢–û–ì–û –ó–ê–ì–†–£–ñ–ï–ù–û –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:")
        print(f"   ‚Ä¢ –ó–∞–ø–∏—Å–µ–π: {len(final_data):,}")
        print(f"   ‚Ä¢ –†–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤: {final_data['restaurant_name'].nunique()}")
        print(f"   ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç: {final_data['date'].nunique():,}")
        print(f"   ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {final_data['date'].min()} ‚Üí {final_data['date'].max()}")
        
        return final_data
    
    def load_restaurant_locations(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç GPS –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—Å–µ—Ö —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤"""
        try:
            with open(self.locations_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return {r['name']: r for r in data['restaurants']}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {e}")
            return {}
    
    def get_weather_with_cache(self, lat, lon, date):
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–≥–æ–¥—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∞"""
        cache_key = f"{lat:.3f}_{lon:.3f}_{date}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if cache_key in self.weather_cache:
            return self.weather_cache[cache_key]
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º
        try:
            params = {
                'latitude': lat,
                'longitude': lon,
                'start_date': date,
                'end_date': date,
                'hourly': 'temperature_2m,precipitation,weather_code,wind_speed_10m,relative_humidity_2m',
                'timezone': 'Asia/Jakarta'
            }
            
            response = requests.get(self.weather_api_url, params=params, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                hourly = data.get('hourly', {})
                
                if hourly and len(hourly.get('time', [])) > 0:
                    temps = hourly.get('temperature_2m', [28])
                    precipitation = hourly.get('precipitation', [0])
                    weather_codes = hourly.get('weather_code', [0])
                    wind_speeds = hourly.get('wind_speed_10m', [5])
                    humidity = hourly.get('relative_humidity_2m', [75])
                    
                    weather_summary = {
                        'temperature': np.mean(temps) if temps else 28,
                        'rain': sum(precipitation) if precipitation else 0,
                        'wind': max(wind_speeds) if wind_speeds else 5,
                        'humidity': np.mean(humidity) if humidity else 75,
                        'condition': self._weather_code_to_condition(
                            max(set(weather_codes), key=weather_codes.count) if weather_codes else 0
                        )
                    }
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                    self.weather_cache[cache_key] = weather_summary
                    return weather_summary
            
            return None
        except Exception as e:
            return None
    
    def _weather_code_to_condition(self, code):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç WMO –∫–æ–¥ –≤ —É—Å–ª–æ–≤–∏–µ"""
        if code == 0:
            return 'Clear'
        elif code in [1, 2, 3]:
            return 'Clouds'
        elif code in [45, 48]:
            return 'Fog'
        elif code in [51, 53, 55, 56, 57, 61, 63, 65, 66, 67, 80, 81, 82]:
            return 'Rain'
        elif code in [95, 96, 99]:
            return 'Thunderstorm'
        else:
            return 'Unknown'
    
    def run_large_scale_analysis(self, sample_size=10000, batch_size=100):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –º–∞—Å—à—Ç–∞–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        print(f"üåç –ó–ê–ü–£–°–ö –ú–ê–°–®–¢–ê–ë–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê ({sample_size:,} –ó–ê–ü–ò–°–ï–ô)")
        print("=" * 60)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        locations = self.load_restaurant_locations()
        large_data = self.get_large_sample_data(sample_size)
        
        if not locations:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö —Ä–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤")
            return None
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
        restaurants_with_coords = [name for name in large_data['restaurant_name'].unique() 
                                  if name in locations]
        
        print(f"üìç –†–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: {len(restaurants_with_coords)}")
        
        filtered_data = large_data[large_data['restaurant_name'].isin(restaurants_with_coords)]
        
        print(f"üéØ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(filtered_data):,} –∑–∞–ø–∏—Å–µ–π")
        
        # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        all_weather_data = []
        processed = 0
        
        print("üå§Ô∏è –°–±–æ—Ä –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏...")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω-–¥–∞—Ç–∞
        unique_combinations = filtered_data[['restaurant_name', 'date']].drop_duplicates()
        
        print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Ä–µ—Å—Ç–æ—Ä–∞–Ω-–¥–∞—Ç–∞: {len(unique_combinations):,}")
        
        for i in range(0, len(unique_combinations), batch_size):
            batch = unique_combinations.iloc[i:i+batch_size]
            
            if i % 1000 == 0:
                print(f"   –ë–∞—Ç—á {i//batch_size + 1}: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(batch)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π...")
            
            for _, row in batch.iterrows():
                restaurant_name = row['restaurant_name']
                date = row['date']
                
                if restaurant_name in locations:
                    location = locations[restaurant_name]
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–≥–æ–¥—É
                    weather = self.get_weather_with_cache(
                        location['latitude'], 
                        location['longitude'], 
                        date
                    )
                    
                    if weather:
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–∂ –¥–ª—è —ç—Ç–æ–≥–æ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å
                        day_data = filtered_data[
                            (filtered_data['restaurant_name'] == restaurant_name) & 
                            (filtered_data['date'] == date)
                        ]
                        
                        if not day_data.empty:
                            record = {
                                'restaurant': restaurant_name,
                                'date': date,
                                'zone': location.get('zone', 'Unknown'),
                                'area': location.get('area', 'Unknown'),
                                'total_sales': day_data['total_sales'].sum(),
                                'total_orders': day_data['total_orders'].sum(),
                                'avg_order_value': day_data['avg_order_value'].mean(),
                                'cancelled_orders': day_data['grab_cancelled'].fillna(0).sum(),
                                'temperature': weather['temperature'],
                                'rain': weather['rain'],
                                'wind': weather['wind'],
                                'humidity': weather['humidity'],
                                'condition': weather['condition'],
                                'day_of_week': day_data['day_of_week'].iloc[0]
                            }
                            all_weather_data.append(record)
                
                processed += 1
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
                if processed % 100 == 0:
                    time.sleep(1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—ç—à –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
                if processed % 500 == 0:
                    self._save_cache()
            
            if i % 1000 == 0:
                print(f"   –ó–∞–≤–µ—Ä—à–µ–Ω –±–∞—Ç—á {i//batch_size + 1}, —Å–æ–±—Ä–∞–Ω–æ {len(all_weather_data)} –∑–∞–ø–∏—Å–µ–π")
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫—ç—à–∞
        self._save_cache()
        
        if not all_weather_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        df = pd.DataFrame(all_weather_data)
        print(f"\n‚úÖ –°–æ–±—Ä–∞–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {len(df):,} –∑–∞–ø–∏—Å–µ–π")
        
        results = self._analyze_large_scale_patterns(df)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_results(results)
        
        return results
    
    def _analyze_large_scale_patterns(self, df):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–µ"""
        print(f"
üåç –ú–ê–°–®–¢–ê–ë–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û–ì–û–î–ù–´–• –ó–ê–ö–û–ù–û–ú–ï–†–ù–û–°–¢–ï–ô")
        print("=" * 55)
        
        results = {
            'total_observations': len(df),
            'restaurants_analyzed': df['restaurant'].nunique(),
            'date_range': (df['date'].min(), df['date'].max()),
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_sales = df['total_sales'].mean()
        avg_orders = df['total_orders'].mean()
        
        print(f"üí∞ –ë–ê–ó–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ–¥–∞–∂–∏: {avg_sales:,.0f} IDR/–¥–µ–Ω—å")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ –∑–∞–∫–∞–∑—ã: {avg_orders:.1f}/–¥–µ–Ω—å")
        print(f"   ‚Ä¢ –ù–∞–±–ª—é–¥–µ–Ω–∏–π: {len(df):,}")
        print(f"   ‚Ä¢ –†–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤: {df['restaurant'].nunique()}")
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –î–û–ñ–î–ï–í–û–ô –ê–ù–ê–õ–ò–ó —Å –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–æ–π
        print(f"
üåßÔ∏è –î–ï–¢–ê–õ–¨–ù–´–ô –î–û–ñ–î–ï–í–û–ô –ê–ù–ê–õ–ò–ó (–ë–û–õ–¨–®–ê–Ø –í–´–ë–û–†–ö–ê):")
        rain_ranges = [
            (0, 0.1, "–°—É—Ö–æ"),
            (0.1, 1, "–û—á–µ–Ω—å –ª–µ–≥–∫–∏–π –¥–æ–∂–¥—å"),
            (1, 3, "–õ–µ–≥–∫–∏–π –¥–æ–∂–¥—å"),
            (3, 6, "–£–º–µ—Ä–µ–Ω–Ω—ã–π –¥–æ–∂–¥—å"),
            (6, 12, "–°–∏–ª—å–Ω—ã–π –¥–æ–∂–¥—å"),
            (12, 25, "–û—á–µ–Ω—å —Å–∏–ª—å–Ω—ã–π –¥–æ–∂–¥—å"),
            (25, 100, "–õ–∏–≤–µ–Ω—å")
        ]
        
        rain_analysis = {}
        for min_rain, max_rain, desc in rain_ranges:
            rain_data = df[(df['rain'] >= min_rain) & (df['rain'] < max_rain)]
            if len(rain_data) >= 30:  # –ú–∏–Ω–∏–º—É–º 30 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
                rain_avg_sales = rain_data['total_sales'].mean()
                rain_avg_orders = rain_data['total_orders'].mean()
                rain_avg_cancelled = rain_data['cancelled_orders'].mean()
                sales_impact = ((rain_avg_sales - avg_sales) / avg_sales * 100)
                orders_impact = ((rain_avg_orders - avg_orders) / avg_orders * 100)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å
                _, p_value_sales = stats.ttest_1samp(rain_data['total_sales'], avg_sales)
                _, p_value_orders = stats.ttest_1samp(rain_data['total_orders'], avg_orders)
                
                rain_analysis[desc] = {
                    'rain_range': f"{min_rain}-{max_rain}–º–º",
                    'sales_impact': sales_impact,
                    'orders_impact': orders_impact,
                    'avg_cancelled': rain_avg_cancelled,
                    'count': len(rain_data),
                    'p_value_sales': p_value_sales,
                    'p_value_orders': p_value_orders,
                    'significant_sales': p_value_sales < 0.05,
                    'significant_orders': p_value_orders < 0.05
                }
                
                # –ó–Ω–∞—á–∏–º–æ—Å—Ç—å
                sales_sig = "üìà –ó–ù–ê–ß–ò–ú–û" if p_value_sales < 0.05 else "‚û°Ô∏è –¢—Ä–µ–Ω–¥"
                orders_sig = "üìà –ó–ù–ê–ß–ò–ú–û" if p_value_orders < 0.05 else "‚û°Ô∏è –¢—Ä–µ–Ω–¥"
                
                print(f"   {desc} ({min_rain}-{max_rain}–º–º): {len(rain_data):,} –¥–Ω–µ–π")
                print(f"      üí∞ –ü—Ä–æ–¥–∞–∂–∏: {sales_impact:+.1f}% ({sales_sig}, p={p_value_sales:.3f})")
                print(f"      üì¶ –ó–∞–∫–∞–∑—ã: {orders_impact:+.1f}% ({orders_sig}, p={p_value_orders:.3f})")
                print(f"      ‚ùå –û—Ç–º–µ–Ω—ã: {rain_avg_cancelled:.1f}/–¥–µ–Ω—å")
        
        # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        print(f"
üå°Ô∏è –¢–ï–ú–ü–ï–†–ê–¢–£–†–ù–´–ô –ê–ù–ê–õ–ò–ó:")
        temp_ranges = [
            (0, 25, "–ü—Ä–æ—Ö–ª–∞–¥–Ω–æ"),
            (25, 27, "–ö–æ–º—Ñ–æ—Ä—Ç–Ω–æ"), 
            (27, 29, "–¢–µ–ø–ª–æ"),
            (29, 31, "–ñ–∞—Ä–∫–æ"),
            (31, 50, "–û—á–µ–Ω—å –∂–∞—Ä–∫–æ")
        ]
        
        temp_analysis = {}
        for min_temp, max_temp, desc in temp_ranges:
            temp_data = df[(df['temperature'] >= min_temp) & (df['temperature'] < max_temp)]
            if len(temp_data) >= 50:
                temp_avg_sales = temp_data['total_sales'].mean()
                sales_impact = ((temp_avg_sales - avg_sales) / avg_sales * 100)
                
                _, p_value = stats.ttest_1samp(temp_data['total_sales'], avg_sales)
                
                temp_analysis[desc] = {
                    'sales_impact': sales_impact,
                    'count': len(temp_data),
                    'avg_temp': temp_data['temperature'].mean(),
                    'p_value': p_value,
                    'significant': p_value < 0.05
                }
                
                significance = "üìà –ó–ù–ê–ß–ò–ú–û" if p_value < 0.05 else "‚û°Ô∏è –¢—Ä–µ–Ω–¥"
                print(f"   {desc} ({temp_data['temperature'].mean():.1f}¬∞C): {sales_impact:+.1f}% ({significance}, {len(temp_data):,} –¥–Ω–µ–π)")
        
        # –í–µ—Ç—Ä–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑
        print(f"
üí® –í–ï–¢–†–û–í–û–ô –ê–ù–ê–õ–ò–ó:")
        wind_ranges = [
            (0, 8, "–®—Ç–∏–ª—å"),
            (8, 15, "–õ–µ–≥–∫–∏–π –≤–µ—Ç–µ—Ä"),
            (15, 25, "–£–º–µ—Ä–µ–Ω–Ω—ã–π –≤–µ—Ç–µ—Ä"),
            (25, 50, "–°–∏–ª—å–Ω—ã–π –≤–µ—Ç–µ—Ä")
        ]
        
        wind_analysis = {}
        for min_wind, max_wind, desc in wind_ranges:
            wind_data = df[(df['wind'] >= min_wind) & (df['wind'] < max_wind)]
            if len(wind_data) >= 30:
                wind_avg_sales = wind_data['total_sales'].mean()
                sales_impact = ((wind_avg_sales - avg_sales) / avg_sales * 100)
                
                _, p_value = stats.ttest_1samp(wind_data['total_sales'], avg_sales)
                
                wind_analysis[desc] = {
                    'sales_impact': sales_impact,
                    'count': len(wind_data),
                    'p_value': p_value,
                    'significant': p_value < 0.05
                }
                
                significance = "üìà –ó–ù–ê–ß–ò–ú–û" if p_value < 0.05 else "‚û°Ô∏è –¢—Ä–µ–Ω–¥"
                print(f"   {desc}: {sales_impact:+.1f}% ({significance}, {len(wind_data):,} –¥–Ω–µ–π)")
        
        # –û–±—â–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        correlations = {
            'temperature_sales': df['temperature'].corr(df['total_sales']),
            'rain_sales': df['rain'].corr(df['total_sales']),
            'wind_sales': df['wind'].corr(df['total_sales']),
            'humidity_sales': df['humidity'].corr(df['total_sales']),
            'rain_cancelled': df['rain'].corr(df['cancelled_orders'])
        }
        
        print(f"
üìä –û–ë–©–ò–ï –ö–û–†–†–ï–õ–Ø–¶–ò–ò:")
        for name, value in correlations.items():
            if abs(value) > 0.02:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∞–∂–µ —Å–ª–∞–±—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                print(f"   üìä {name}: {value:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results.update({
            'rain_analysis': rain_analysis,
            'temperature_analysis': temp_analysis,
            'wind_analysis': wind_analysis,
            'correlations': correlations,
            'base_metrics': {
                'avg_sales': avg_sales,
                'avg_orders': avg_orders
            }
        })
        
        return results
    
    def _save_results(self, results):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            os.makedirs('data', exist_ok=True)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –¥–ª—è JSON
            def convert_numpy(obj):
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                return obj
            
            filename = 'data/large_scale_weather_analysis.json'
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=convert_numpy)
            
            print(f"
üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

def main():
    """–ó–∞–ø—É—Å–∫ –º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    analyzer = LargeScaleWeatherAnalyzer()
    
    print("ÔøΩÔøΩ –ú–ê–°–®–¢–ê–ë–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û–ì–û–î–ù–´–• –ó–ê–ö–û–ù–û–ú–ï–†–ù–û–°–¢–ï–ô")
    print("=" * 65)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å –±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–æ–π
    results = analyzer.run_large_scale_analysis(sample_size=10000, batch_size=50)
    
    if results:
        print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {results['total_observations']:,} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"üè™ –†–µ—Å—Ç–æ—Ä–∞–Ω–æ–≤: {results['restaurants_analyzed']}")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥: {results['date_range'][0]} ‚Üí {results['date_range'][1]}")
        
        print("
üí° –î–û–°–¢–ò–ñ–ï–ù–ò–Ø:")
        print("   ‚úÖ –ë–æ–ª—å—à–∞—è –≤—ã–±–æ—Ä–∫–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å")
        print("   ‚úÖ –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –¥–æ–∂–¥–µ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        print("   ‚úÖ P-–∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞")
        print("   ‚úÖ –ì–æ—Ç–æ–≤–æ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã")

if __name__ == "__main__":
    main()
